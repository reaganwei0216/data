{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16實作十六：文本翻譯.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRVATYOgJs1b"
      },
      "source": [
        "#西班牙文翻英文\n",
        "#資料來源http://www.manythings.org/anki/\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd0jw-eC3jEh"
      },
      "source": [
        "#資料前處理：\n",
        "# 將每個句子增加開始與結束標記\n",
        "# 刪除特殊符號\n",
        "# 建立單詞索引\n",
        "# 將句子進行填充\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    w = w.rstrip().strip()\n",
        "    w = '<start> ' + w + ' <end>' #開始與結束\n",
        "    return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opI2GzOt479E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5997ba-9d24-4493-c08e-443f1bb93c55"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHn4Dct23jEm"
      },
      "source": [
        "# 清除重音\n",
        "# 清理句子\n",
        "# 整理回傳的句子\n",
        "def create_dataset(path, num_examples):\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "    return zip(*word_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTbSbBz55QtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318de0f9-5f78-49ae-c4cc-a40b71d2e9a8"
      },
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmMZQpdO60dt"
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIOn8RCNDJXG"
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "    # 建立輸入與預測對象\n",
        "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnxC7q-j3jFD"
      },
      "source": [
        "# 將數據大小控制在30000筆\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor) #計算最大長度的張量"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QILQkOs3jFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35e82895-3f27-447a-f91d-b03e77844d72"
      },
      "source": [
        "# 拆分80%訓練、20%測試\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# 確認長度\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24000, 24000, 6000, 6000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJPmLZGMeD5q"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXukARTDd7MT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5662ad-5e30-4cf0-bad0-0268b806849e"
      },
      "source": [
        "print (\"輸入; 文字索引\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"目標; 文字索引\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "輸入; 文字索引\n",
            "1 ----> <start>\n",
            "23 ----> te\n",
            "428 ----> encontre\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "目標; 文字索引\n",
            "1 ----> <start>\n",
            "4 ----> i\n",
            "331 ----> found\n",
            "6 ----> you\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3alGSTdBjA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d5c37ac-5fea-4734-812d-b37bf47692c4"
      },
      "source": [
        "len(input_tensor_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqHsArVZ3jFS"
      },
      "source": [
        "#透過tf.data，將input_tensor_train與target_tensor_train做資料整理，以提升運算效率\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "#依據input_tensor_train筆數建立BUFFER，進行shuffle\n",
        "BATCH_SIZE = 64\n",
        "#取整數作為每一次epoch的steps\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE \n",
        "embedding_dim = 256\n",
        "#GRU的單元數\n",
        "units = 1024\n",
        "#預測內容是西班牙文，預測目標是英文\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yyU04eOBaX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f95613e-7040-4fe0-9581-f245d127e04d"
      },
      "source": [
        "input_tensor_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,   23,  428, ...,    0,    0,    0],\n",
              "       [   1,   54, 3123, ...,    0,    0,    0],\n",
              "       [   1,    4,    8, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   1,    9,   17, ...,    0,    0,    0],\n",
              "       [   1, 3028,   32, ...,    0,    0,    0],\n",
              "       [   1,   54,  345, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h43kskwwoo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b906f26a-1e05-4505-e9b5-ed0589db5ba2"
      },
      "source": [
        "next(iter(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 16), dtype=int32, numpy=\n",
              " array([[   1, 1810,   21, ...,    0,    0,    0],\n",
              "        [   1,  100,   53, ...,    0,    0,    0],\n",
              "        [   1,   28,    7, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [   1,   26,  142, ...,    0,    0,    0],\n",
              "        [   1,  489,  273, ...,    0,    0,    0],\n",
              "        [   1,   53,  647, ...,    0,    0,    0]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(64, 11), dtype=int32, numpy=\n",
              " array([[   1,    4,   76,    9,  146,  595,    3,    2,    0,    0,    0],\n",
              "        [   1,    4,  103,   47,   15,   36,    3,    2,    0,    0,    0],\n",
              "        [   1,   20,   90,   12,  601,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,  280,   31,  765,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1, 1048, 1100,    3,    2,    0,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,   18,   34,  129,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   10,  361,   21,  189,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   10,   11, 1231,   97,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   10,   11,    9,  101,  748,    3,    2,    0,    0,    0],\n",
              "        [   1,    4,  317, 1367,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,  244,  128,   49,   56,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   39,  590,    5,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,  760,   50,   33,  158,    3,    2,    0,    0,    0],\n",
              "        [   1,    4,   18, 1468,  410,    6,    3,    2,    0,    0,    0],\n",
              "        [   1,    4,   22,  221,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,   47,  371,  347,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    4,   18,   34, 2709,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   46,   11,   22,   13,   93,    3,    2,    0,    0,    0],\n",
              "        [   1,    4,  135,  187,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   20,  518, 1434,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,   47,   15,  149,   15,   68,    3,    2,    0,    0],\n",
              "        [   1,   14,   11, 1687,  163,  892,    3,    2,    0,    0,    0],\n",
              "        [   1,  518,   69,   15,   17,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    4,  328,   41,  119, 1277,    3,    2,    0,    0,    0],\n",
              "        [   1,    4,   75, 1814,   41,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    4,   18,    9, 1751,   49,   78,    3,    2,    0,    0],\n",
              "        [   1,   27,  603,    9,  153,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,  281,   89,    3,    2,    0,    0,    0,    0,    0,    0],\n",
              "        [   1,   13,  211,    8,  793,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   86, 2024,    3,    2,    0,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,   65,  411, 1067,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   10,   11,   35,    9, 2714,    3,    2,    0,    0,    0],\n",
              "        [   1, 1583,   10,   15,   17,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    4,   87,   12,  438,   10,    3,    2,    0,    0,    0],\n",
              "        [   1,   30,   12,  295,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,   43,   32,   11,  991,    3,    2,    0,    0,    0],\n",
              "        [   1,    5,   11,  741,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   14,  311,  142,   61,  890,    3,    2,    0,    0,    0],\n",
              "        [   1,    4,  177, 2875,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   10,   26,    9,  856,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    6,   42,   10,  131,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    4,   63,  371,  803,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    5,    8,  330,  131,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   10,   11,   66,  155,  748,    3,    2,    0,    0,    0],\n",
              "        [   1,   14,  513,    3,    2,    0,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,   76,    9, 2213, 3709,    3,    2,    0,    0,    0],\n",
              "        [   1,  459,   10,  203, 1414,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   20,   11,  204,   15,  136,    3,    2,    0,    0,    0],\n",
              "        [   1,  912,  323,   37,    2,    0,    0,    0,    0,    0,    0],\n",
              "        [   1,   14,   11,  330,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   16,   77,   13, 1469,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    5,  292,   40,  148,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   10,   26,    9, 2586,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,   56,  497,   17,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,    4,   26,  130,  759,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    6,   25,   12,   73,  126,    3,    2,    0,    0,    0],\n",
              "        [   1,  821,   51,   53,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,    5,  179,   15,  295,    3,    2,    0,    0,    0,    0],\n",
              "        [   1, 1221, 3858,   17,    3,    2,    0,    0,    0,    0,    0],\n",
              "        [   1,   20,    8,   34,  172,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,  116,   81,  119,  126,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    4,  135,   21,  542,    3,    2,    0,    0,    0,    0],\n",
              "        [   1,    4,   46,   13,  229,   33,    3,    2,    0,    0,    0],\n",
              "        [   1,    4,   47,    9,  206,    3,    2,    0,    0,    0,    0]],\n",
              "       dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc6-NK1GtWQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467e1556-d43f-4ab6-ff96-3aafb29ff942"
      },
      "source": [
        "#生成迭代器觀察內容與目標\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 16]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVXeIvVyxXt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e983a8-6ea9-4cc6-d9fd-179044d8a95c"
      },
      "source": [
        "example_target_batch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 11), dtype=int32, numpy=\n",
              "array([[   1,   10,   11,  412,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,  255,   17,   31, 1259,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,   32,    9,  625, 1864,   37,    2,    0,    0,    0,    0],\n",
              "       [   1,   14,   51,    9, 2589,  449,    3,    2,    0,    0,    0],\n",
              "       [   1,    4,   26, 2619,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,  124,   31,  312,   43,    7,    2,    0,    0,    0,    0],\n",
              "       [   1,    8,   57,  365,  662,    7,    2,    0,    0,    0,    0],\n",
              "       [   1,    8,   19, 2398, 3097,    7,    2,    0,    0,    0,    0],\n",
              "       [   1,    4, 1132,   19, 3047,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,   20,  168,  137,  186,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,  279,   15,    5,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,   10,   11,   31,  209,  803,    3,    2,    0,    0,    0],\n",
              "       [   1,    4,   18,    9, 2624,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,   75,    6,   36,   80,   81,    7,    2,    0,    0,    0],\n",
              "       [   1,  379,   11,  217,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,   14,    8,  946,    9,  282,    3,    2,    0,    0,    0],\n",
              "       [   1,  244,  128,   80,   17,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,    4,   25,   12,  185,   13,  201,    3,    2,    0,    0],\n",
              "       [   1,    4,   47,   15,  161,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,   25,    4,  185,   21,  324,    7,    2,    0,    0,    0],\n",
              "       [   1,    5,    8,    9, 3624,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,   14,   11,   21,  782,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,   16,   23,  269,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,  185,   31,  532,   37,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,    4,   62,   79,  819,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,   28,   93,  451,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,   16,   29,   66,  990,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,  195,    8,  182,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,    8,   10,   69,    7,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,   46,   11,  264,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,   16,   23, 2126,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,   19,    8,   21,  229,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,    5,  361,    3,    2,    0,    0,    0,    0,    0,    0],\n",
              "       [   1,    4,   77, 1500, 4695,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,    4,  656,   12,  307,    5,    3,    2,    0,    0,    0],\n",
              "       [   1,   10,   11,   33,  526,   11,  344,    3,    2,    0,    0],\n",
              "       [   1,    4,   25, 1180,   72,   10,    3,    2,    0,    0,    0],\n",
              "       [   1,   36,   20,  196,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,   60,  271,  436,    7,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,    4,  114,    5,  121,    6,    3,    2,    0,    0,    0],\n",
              "       [   1,    5,  706,    6,   23,  330,    3,    2,    0,    0,    0],\n",
              "       [   1,   60,  815,   57,    7,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,    4,  192,   21, 2094,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,    4,  169,   36,   15, 1330,    3,    2,    0,    0,    0],\n",
              "       [   1,    4,   62,  225,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,   28,   88,  101,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,   67,    8,  453,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,   14,    8,   48,  549,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,   94,   17,   80,    6,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,    4,  173,    5,    9, 3075,    3,    2,    0,    0,    0],\n",
              "       [   1,   13,  465,  551,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,    5,   75,   77,   10,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,   19,    8,    9,  864,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,   88,   91,   37,    2,    0,    0,    0,    0,    0,    0],\n",
              "       [   1,    4,   30,   12,  477,   41,    3,    2,    0,    0,    0],\n",
              "       [   1,  304,   10,  543,  724,   10,    3,    2,    0,    0,    0],\n",
              "       [   1,  260,  106,  590,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,  806,   31,  344,  109,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,   60,   26,   20,  350,    7,    2,    0,    0,    0,    0],\n",
              "       [   1,   24,    6,    9, 1155,    7,    2,    0,    0,    0,    0],\n",
              "       [   1,  111,   31, 2890,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,    5,   11,  375,    3,    2,    0,    0,    0,    0,    0],\n",
              "       [   1,    4,   35, 1654, 2372,    3,    2,    0,    0,    0,    0],\n",
              "       [   1,   14,    8,  288,   15, 4337,    3,    2,    0,    0,    0]],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz #BATCH_SIZE\n",
        "    self.enc_units = enc_units #單元數\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) #每一個單詞轉為Embedding\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform') #均勻初始化\n",
        "\n",
        "  def call(self, x, hidden): #做一層embedding+GRU\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden) #每一次初始化為Hidden的變數\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self): #建立空的初始化\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60gSVh05Jl6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd78b200-3b71-4dfd-be45-c661a82a3794"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE) #依據vocab_inp_size、embedding_dim、單元數、BATCH_SIZE建立Encoder\n",
        "\n",
        "# 輸入的樣本\n",
        "sample_hidden = encoder.initialize_hidden_state() #依據Batch_sz與enc_units初始化\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden) #觀察一下預測內容與具備GRU單元數的隱藏層樣態\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape)) #sample_output（批次大小、訓練資料長度、單元數）\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape)) #sample_hidden（批次大小、單元數）"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umohpBN2OM94"
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__() #繼承TF的BahdanauAttention\n",
        "    self.W1 = tf.keras.layers.Dense(units) #依據GRU的單元數進行Dense\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # 執行加法計算分數，先將讓query多一個維度，相加之後做一個tanh，獲得分數，score = FC(tanh(FC(EO) + FC(H)))\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "    # attention weights = softmax(score, axis = 1) \n",
        "    attention_weights = tf.nn.softmax(score, axis=1) \n",
        "    # context_vector = sum(attention weights * EO, axis = 1)\n",
        "    context_vector = attention_weights * values \n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k534zTHiDjQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c449a0-3c70-46ae-dd80-83b7ac33683a"
      },
      "source": [
        "attention_layer = BahdanauAttention(10) #Attention的強度\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output) #將初始化空的sample_hidden與要進行預測內容\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ_B3mhW3jFk"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz): #詞彙、embedding維度、單元數、批次大小\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size) \n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # 透過BahdanauAttention建立context_vector、attention_weights\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # 做一次embedding\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x整合後的大小batch_size、embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # 將x給GRU計算後回報結果與狀態\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # 資料維度整理\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # 做線性轉換後輸出\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5UY8wko3jFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd24432-c5a8-4782-dc68-3e732b918eb0"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE) #依據詞彙、embedding維度、單元數、批次大小進行Decoder\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)), #隨機產生批次大小的資料作為起始值、sample_hidden初始值、預測內容\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "source": [
        "#定義優化器、衡量標準\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0)) #將數字轉換為邏輯值\n",
        "  loss_ = loss_object(real, pred) #透過loss_object做Crossentropy計算\n",
        "  #透過tf.cast做函數轉換，如：1轉True\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj8bXQTgNwrF"
      },
      "source": [
        "#記錄每一次計算的Checkpoints\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC9ArXSsVfqn"
      },
      "source": [
        "@tf.function #加上tf.function修飾器\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    #通過編碼器傳遞輸入，編碼器產生「編碼器輸出」和「編碼器隱藏狀態」。\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "    #將「編碼器隱藏狀態」傳給「解碼器的隱藏狀態」\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # 將預測結果作為下一個輸入\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # 解碼器返回「預測值」和「解碼器隱藏狀態」。\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "      # 將答案與predictions做Loss計算\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # 將預測目標，作為下一個解碼器dec_input的輸入\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "  \n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  #紀錄每一次的自動微分結果\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  #進行優化器計算\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddefjBMa3jF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61f1090c-718c-4d04-aca5-976799dfa1ae"
      },
      "source": [
        "#開始訓練模型\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "  #將預測內容、預測目標放入\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "  # 每兩個epochs就儲存一次checkpoint\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.6868\n",
            "Epoch 1 Batch 100 Loss 2.1530\n",
            "Epoch 1 Batch 200 Loss 1.7936\n",
            "Epoch 1 Batch 300 Loss 1.6646\n",
            "Epoch 1 Loss 2.0365\n",
            "Time taken for 1 epoch 42.73405861854553 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.5754\n",
            "Epoch 2 Batch 100 Loss 1.4577\n",
            "Epoch 2 Batch 200 Loss 1.3582\n",
            "Epoch 2 Batch 300 Loss 1.2172\n",
            "Epoch 2 Loss 1.3887\n",
            "Time taken for 1 epoch 33.29595971107483 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0997\n",
            "Epoch 3 Batch 100 Loss 0.9315\n",
            "Epoch 3 Batch 200 Loss 0.9037\n",
            "Epoch 3 Batch 300 Loss 0.8976\n",
            "Epoch 3 Loss 0.9723\n",
            "Time taken for 1 epoch 32.43663215637207 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.7002\n",
            "Epoch 4 Batch 100 Loss 0.6771\n",
            "Epoch 4 Batch 200 Loss 0.5618\n",
            "Epoch 4 Batch 300 Loss 0.6263\n",
            "Epoch 4 Loss 0.6640\n",
            "Time taken for 1 epoch 33.00522756576538 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.4257\n",
            "Epoch 5 Batch 100 Loss 0.3978\n",
            "Epoch 5 Batch 200 Loss 0.5117\n",
            "Epoch 5 Batch 300 Loss 0.4234\n",
            "Epoch 5 Loss 0.4544\n",
            "Time taken for 1 epoch 32.55444025993347 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.2512\n",
            "Epoch 6 Batch 100 Loss 0.4008\n",
            "Epoch 6 Batch 200 Loss 0.3353\n",
            "Epoch 6 Batch 300 Loss 0.4329\n",
            "Epoch 6 Loss 0.3165\n",
            "Time taken for 1 epoch 32.86260485649109 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.2414\n",
            "Epoch 7 Batch 100 Loss 0.2300\n",
            "Epoch 7 Batch 200 Loss 0.2425\n",
            "Epoch 7 Batch 300 Loss 0.2852\n",
            "Epoch 7 Loss 0.2272\n",
            "Time taken for 1 epoch 32.67666983604431 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1491\n",
            "Epoch 8 Batch 100 Loss 0.1380\n",
            "Epoch 8 Batch 200 Loss 0.1723\n",
            "Epoch 8 Batch 300 Loss 0.1455\n",
            "Epoch 8 Loss 0.1678\n",
            "Time taken for 1 epoch 33.09664869308472 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.1147\n",
            "Epoch 9 Batch 100 Loss 0.1029\n",
            "Epoch 9 Batch 200 Loss 0.0847\n",
            "Epoch 9 Batch 300 Loss 0.1332\n",
            "Epoch 9 Loss 0.1300\n",
            "Time taken for 1 epoch 32.55344867706299 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.1158\n",
            "Epoch 10 Batch 100 Loss 0.1114\n",
            "Epoch 10 Batch 200 Loss 0.0958\n",
            "Epoch 10 Batch 300 Loss 0.1076\n",
            "Epoch 10 Loss 0.1058\n",
            "Time taken for 1 epoch 33.03606629371643 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbQpyYs13jF_"
      },
      "source": [
        "#驗證與產生結果\n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp)) #建立最大的輸入與預測目標\n",
        "    #將資料做前處理，如去除符號、轉tensor..等\n",
        "    sentence = preprocess_sentence(sentence) \n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                           maxlen=max_length_inp,\n",
        "                                                           padding='post')    \n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    #透過encoder產生出輸出與狀態\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    #編碼層的狀態一樣給解碼層(dec_hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        # 透過decoder解碼，獲得預測結果、解碼狀態、注意力權重\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # 儲存注意力權重\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "        # 將預測ID回饋到模型\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "        \n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "       \n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "source": [
        "# 繪製注意力視覺化\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl9zUHzg3jGI"
      },
      "source": [
        "# 將模型用來做結果預測\n",
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrAM0FDomq3E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "5bdceaaa-6ae3-429d-fe0c-8bb83ed6578d"
      },
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold here . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUQVLVqUE1YW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "7bd028e2-0626-4eff-f955-b25b56cd0fe6"
      },
      "source": [
        "translate(u'trata de averiguarlo.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> trata de averiguarlo . <end>\n",
            "Predicted translation: try to figure it out . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS9YWFFou4UB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}