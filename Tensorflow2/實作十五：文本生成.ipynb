{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15實作十五：文本生成",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_mS5bq7A9gT"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfi_yEfOZ8Mn"
      },
      "source": [
        "#讀取資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6At2Ro36Zz-d"
      },
      "source": [
        "#莎士比亞的科利奧蘭納斯劇本，是莎士比亞晚期的作品\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceai03amZ1KH",
        "outputId": "f5401678-74c7-4ba6-c180-11b271c004c4"
      },
      "source": [
        "# 讀取資料，並且格式轉換為utf-8\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# 確認\b字數量\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9Qf11CW_Z4Q",
        "outputId": "530692b8-0f68-4964-cd02-70a4bac3a2de"
      },
      "source": [
        "# 觀察前100個字\n",
        "print(text[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC0iPVfL_m3b",
        "outputId": "9576097b-14a9-4f31-e515-0e951929808a"
      },
      "source": [
        "# 觀察不重複字元\n",
        "vocab = sorted(set(text))\n",
        "print('{} 個不重複的文字'.format(len(vocab)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65 個不重複的文字\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLYskJolZ6yd",
        "outputId": "34b6591d-c752-4c33-9687-39cfb6107c6c"
      },
      "source": [
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '$',\n",
              " '&',\n",
              " \"'\",\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '3',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7fooiQyZ92z"
      },
      "source": [
        "#資料前處理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLSZOLgNZ7uj"
      },
      "source": [
        "# 建立每一個文字的代號\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA8nC4Z-aAo4",
        "outputId": "7bf9000a-830d-4b0f-8280-fec5a85ee1c2"
      },
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\n':   0,\n",
            "  ' ' :   1,\n",
            "  '!' :   2,\n",
            "  '$' :   3,\n",
            "  '&' :   4,\n",
            "  \"'\" :   5,\n",
            "  ',' :   6,\n",
            "  '-' :   7,\n",
            "  '.' :   8,\n",
            "  '3' :   9,\n",
            "  ':' :  10,\n",
            "  ';' :  11,\n",
            "  '?' :  12,\n",
            "  'A' :  13,\n",
            "  'B' :  14,\n",
            "  'C' :  15,\n",
            "  'D' :  16,\n",
            "  'E' :  17,\n",
            "  'F' :  18,\n",
            "  'G' :  19,\n",
            "  ...\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH5a_Tn0aBgs",
        "outputId": "ec5f0870-d865-4d3a-eccc-8b1708e202f3"
      },
      "source": [
        "# 展示前面10個文字轉換後的代號\n",
        "print('文字：',text[:10],'代號：',text_as_int[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "文字： First Citi 代號： [18 47 56 57 58  1 15 47 58 47]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObAePKpiaCwU",
        "outputId": "cbb603fd-6c6c-432a-ac1e-946f35737c31"
      },
      "source": [
        "#設定最長輸入的句子\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "#建立訓練資料與預測目標\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "    print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSgy2BeAakOZ"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2cqyq6EaoMm",
        "outputId": "a8fe3a4f-f76b-4fe0-aee2-1cebd890693c"
      },
      "source": [
        "#前一個輸入的文字，預測下一個輸入的文字\n",
        "for input_example, target_example in  dataset.take(1):\n",
        "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmHVJ5u2apbF",
        "outputId": "3b8e6272-8241-42ae-98df-a1ec63901c67"
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))\n",
        "#以First為例，用F去預測i，用i去預測r"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 18 ('F')\n",
            "  expected output: 47 ('i')\n",
            "Step    1\n",
            "  input: 47 ('i')\n",
            "  expected output: 56 ('r')\n",
            "Step    2\n",
            "  input: 56 ('r')\n",
            "  expected output: 57 ('s')\n",
            "Step    3\n",
            "  input: 57 ('s')\n",
            "  expected output: 58 ('t')\n",
            "Step    4\n",
            "  input: 58 ('t')\n",
            "  expected output: 1 (' ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3AXR6JwatyJ",
        "outputId": "ce50821e-932f-4d57-a09f-8eda2d54a499"
      },
      "source": [
        "# 加上BUFFER_SIZE與BATCH_SIZE\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpt4_O2rbB3l"
      },
      "source": [
        "#建立模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjxRhf1BaxpB"
      },
      "source": [
        "# 建立以65字元vocab_size\n",
        "vocab_size = len(vocab)\n",
        "# 設定詞嵌入的維度\n",
        "embedding_dim = 256\n",
        "# 設定RNN所使用的單元數\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6loUBFsVayqi"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "        tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pDRdOa0azme"
      },
      "source": [
        "model = build_model(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNhqcQ6pF1yF",
        "outputId": "5aa2833e-2b11-4567-9471-13c0402626a5"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (批次大小、序列長度、字詞的數量)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65) # (批次大小、序列長度、字詞的數量)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZvOvaHubETZ"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dIeBPAlbFO1",
        "outputId": "a1d2cfa4-4be8-48e8-f207-5a46247ae044"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8,  5, 40, 61, 41, 35, 17,  7, 49, 18, 19, 16, 62, 54,  9, 57,  4,\n",
              "       10, 32, 18, 53, 35, 48, 18, 24, 32,  2,  5, 27, 48, 37, 53, 57, 51,\n",
              "       36, 29,  2, 18, 53,  0, 57, 31, 64, 10, 30, 23, 27, 60, 34, 29, 14,\n",
              "       15, 48, 10, 19, 30, 16, 53, 14, 15, 37, 36, 47, 22, 16, 27, 23,  3,\n",
              "        5, 26,  6, 53, 17, 18, 27, 13, 64, 59, 57,  1, 10, 32, 12, 18, 40,\n",
              "       41,  5,  5, 64, 59, 11, 44, 54, 45, 38, 19,  9, 35, 56, 21])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlPjw-UpbGGP",
        "outputId": "17f8c79a-819e-4bc0-c389-74c75f7a6122"
      },
      "source": [
        "print(\"輸入: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"下一個預測的文字: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "輸入: \n",
            " 'kill him?\\n\\nBUCKINGHAM:\\nMy lord, your promise for the earldom,--\\n\\nKING RICHARD III:\\nRichmond! When la'\n",
            "\n",
            "下一個預測的文字: \n",
            " \".'bwcWE-kFGDxp3s&:TFoWjFLT!'OjYosmXQ!Fo\\nsSz:RKOvVQBCj:GRDoBCYXiJDOK$'N,oEFOAzus :T?Fbc''zu;fpgZG3WrI\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE2PQfIAbPll",
        "outputId": "ff70ee38-49ea-4dae-dbf6-3e5bc12e424e"
      },
      "source": [
        "# 設定儲存位置\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n",
        "\n",
        "\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "# 模型compile\n",
        "model.compile(optimizer='adam', loss=loss)\n",
        "history = model.fit(dataset, epochs=10, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 3.2523\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 2.0577\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 11s 59ms/step - loss: 1.7462\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 11s 60ms/step - loss: 1.5706\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.4653\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.4004\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.3493\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.3085\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.2700\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.2368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAhAqcT_b0dC"
      },
      "source": [
        "# 文字生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9aUbQNVb1xR"
      },
      "source": [
        "#讀取模型\n",
        "tf.train.latest_checkpoint(checkpoint_dir)\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq_prD5xb6QR"
      },
      "source": [
        "#建立文字生成函式\n",
        "def generate_text(model, start_string):\n",
        "    # 設定每一個生成的長度\n",
        "    num_generate = 1000\n",
        "    # 轉換文字到向量\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    text_generated = []\n",
        "    #建立預測參數，低的temperature可以有比較多的預測文字，反之高的會產生比較多的不相關的文字\n",
        "    temperature = 1.0\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        # 清空批次的維度資料\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # 預測文字\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "        # 將預測的文字作為下一個輸入\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        #將文字組合起來\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vD_0vl6Xb6j9",
        "outputId": "024d3b71-1a25-4e79-9967-0aafcee87dd5"
      },
      "source": [
        "print(generate_text(model, start_string=u\"First Citizen\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "If would not pata'll better benied of our troop-late\n",
            "to harry my coward propperose to my tender: even so like a ve,\n",
            "To his consent for their counself's roaricute\n",
            "To mons the matter for put thy son thou hast.\n",
            "Nowling methown is ripely fathers' lord\n",
            "revelse your ready too let have been, and than lianlike him.\n",
            "\n",
            "BENVOLIO:\n",
            "The queen is caming steals tas this to-day; mistose, open those world receive\n",
            "The bran of Ross? I will too leave?\n",
            "\n",
            "RIVERS:\n",
            "My lord, how now!\n",
            "\n",
            "PETRUCHIO:\n",
            "If she wind\n",
            "Sith fair better death tell The fools.\n",
            "\n",
            "SAMPSON:\n",
            "This is a banishment doth to you but hath.\n",
            "\n",
            "LEONTES:\n",
            "You are for wants one day.\n",
            "\n",
            "BUCKINGHAM:\n",
            "Why, 'tis crookned as Edward scorn'd\n",
            "Should nd't.\n",
            "\n",
            "PETRUTH:\n",
            "Cut,--then would I do request; it is,\n",
            "So can alike purpose, we will promite thigh--\n",
            "\n",
            "ISABELLA:\n",
            "Away, thou art a worse to the streets.\n",
            "\n",
            "KING RICHARD II:\n",
            "Not say that enome; and all their swords\n",
            "Than blackly and dangers and straws writing where\n",
            "The pronounced beneficious motas swift and deigny:\n",
            "As I keep thither\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAGYq3Uxb8CX"
      },
      "source": [
        "#改善結果的方式，增加EPOCHS次數要改善結果\n",
        "#也可以增加RNN、LSTM來去調整結果\n",
        "#或是調整temperature參數"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}