{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79df324d",
   "metadata": {},
   "source": [
    "ref:9.4 檢測詐騙交易-堆疊法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002f53ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯入函式庫\n",
    "# from sklearn.base import BaseEstimator\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Stacking():\n",
    "# class Stacking(BaseEstimator):\n",
    "\n",
    "    # 定義函式初始化\n",
    "    def __init__(self, learner_levels):\n",
    "        # 接收基學習器、超學習器、以及堆疊中每一層分別有多少學習器\n",
    "        # 複製學習器++\n",
    "        self.level_sizes = []\n",
    "        self.learners = []\n",
    "        self.learner_levels = learner_levels\n",
    "        for learning_level in self.learner_levels:\n",
    "\n",
    "            self.level_sizes.append(len(learning_level))\n",
    "            level_learners = []\n",
    "            for learner in learning_level:\n",
    "                level_learners.append(deepcopy(learner))\n",
    "            self.learners.append(level_learners)\n",
    "\n",
    "    # fit 函式\n",
    "    # 用第i-1層的基學習器預測值來訓練第i層的基學習器\n",
    "    def fit(self, x, y):\n",
    "        # 第1層基學習器的訓練資料即為原始資料\n",
    "        meta_data = [x]\n",
    "        meta_targets = [y]\n",
    "        for i in range(len(self.learners)):\n",
    "            level_size = self.level_sizes[i]\n",
    "\n",
    "            # 建立第i層預測值的儲存空間\n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "            target_z = np.zeros(len(x))\n",
    "\n",
    "            # 取得第i層訓練資料集\n",
    "            train_x = meta_data[i]\n",
    "            train_y = meta_targets[i]\n",
    "\n",
    "            # 建立交叉驗證\n",
    "            KF = KFold(n_splits=3)\n",
    "            meta_index = 0\n",
    "            for train_indices, test_indices in KF.split(x):\n",
    "                for j in range(len(self.learners[i])):\n",
    "                    # 使用前K-1折訓練第j個基學習器\n",
    "                    learner = self.learners[i][j]\n",
    "                    learner.fit(train_x[train_indices], train_y[train_indices])\n",
    "                    # 使用第K折驗證第j個基學習器\n",
    "                    predictions = learner.predict(train_x[test_indices])\n",
    "                    # 儲存第K折第j個基學習器預測結果\n",
    "                    data_z[j][meta_index:meta_index+len(test_indices)] = predictions\n",
    "\n",
    "                # 儲存第i層基學習器的預測結果\n",
    "                # 作為第i+1層基學習器的訓練資料\n",
    "                target_z[meta_index:meta_index+len(test_indices)] = train_y[test_indices]\n",
    "                meta_index += len(test_indices)\n",
    "\n",
    "            # Add the data and targets to the meta data lists\n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "            meta_targets.append(target_z)\n",
    "\n",
    "\n",
    "            # 使用完整的訓練資料來訓練基學習器\n",
    "            for learner in self.learners[i]:\n",
    "                    learner.fit(train_x, train_y)\n",
    "\n",
    "    # predict 函式\n",
    "    def predict(self, x):\n",
    "\n",
    "        # 儲存每一層的預測\n",
    "        meta_data = [x]\n",
    "        for i in range(len(self.learners)):\n",
    "            level_size = self.level_sizes[i]\n",
    "\n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "\n",
    "            test_x = meta_data[i]\n",
    "\n",
    "            KF = KFold(n_splits=3)\n",
    "            for train_indices, test_indices in KF.split(x):\n",
    "                for j in range(len(self.learners[i])):\n",
    "\n",
    "                    learner = self.learners[i][j]\n",
    "                    predictions = learner.predict(test_x)\n",
    "                    data_z[j] = predictions\n",
    "\n",
    "            # 儲存第i層基學習器的預測結果\n",
    "            # 作為第i+1層基學習器的輸入\n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "\n",
    "        # 傳回預測結果\n",
    "        return meta_data[-1]\n",
    "\n",
    "    # predict_proba 函式\n",
    "    def predict_proba(self, x):\n",
    "\n",
    "        # 儲存每一層的預測\n",
    "        meta_data = [x]\n",
    "        for i in range(len(self.learners)-1):\n",
    "            level_size = self.level_sizes[i]\n",
    "\n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "\n",
    "            test_x = meta_data[i]\n",
    "\n",
    "            KF = KFold(n_splits=5)\n",
    "            for train_indices, test_indices in KF.split(x):\n",
    "                for j in range(len(self.learners[i])):\n",
    "\n",
    "                    learner = self.learners[i][j]\n",
    "                    predictions = learner.predict(test_x)\n",
    "                    data_z[j] = predictions\n",
    "\n",
    "            # 儲存第i層基學習器的預測結果\n",
    "            # 作為第i+1層基學習器的輸入\n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "\n",
    "        # 傳回預測結果\n",
    "        learner = self.learners[-1][-1]\n",
    "        return learner.predict_proba(meta_data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ff0f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 第 1 部分 ---\n",
    "# 載入函式庫與資料集\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "bc = load_breast_cancer()\n",
    "\n",
    "train_x, train_y = bc.data[:400], bc.target[:400]\n",
    "test_x, test_y = bc.data[400:], bc.target[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7498f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 第 2 部分 ---\n",
    "# 建立基學習器與超學習器\n",
    "# 將基學習器放到串列中\n",
    "# base_learners = []\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "# base_learners.append(knn)\n",
    "\n",
    "dtr = DecisionTreeClassifier(max_depth=4, random_state=2)\n",
    "# base_learners.append(dtr)\n",
    "\n",
    "mlpc = MLPClassifier(hidden_layer_sizes =(100, ), random_state=2)\n",
    "# base_learners.append(mlpc)\n",
    "\n",
    "base_classifiers = [knn,dtr,mlpc]\n",
    "\n",
    "meta_learners = [LogisticRegression(solver = 'liblinear')] # 超學習器為邏輯斯迴歸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01c7feb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Stacking at 0x1665a61be08>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble = Stacking(learner_levels = [base_classifiers,\n",
    "                                      meta_learners])\n",
    "ensemble\n",
    "\n",
    "# ensemble.fit(x_train, y_train)\n",
    "# print('Stacking f1', metrics.f1_score(y_test, ensemble.predict(x_test)))\n",
    "# print('Stacking recall', metrics.recall_score(y_test, ensemble.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c96ef0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[KNeighborsClassifier(n_neighbors=2),\n",
       "  DecisionTreeClassifier(max_depth=4, random_state=2),\n",
       "  MLPClassifier(random_state=2)],\n",
       " [LogisticRegression(solver='liblinear')]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67627e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\011305\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking f1 0.944\n",
      "Stacking recall 0.9076923076923077\n",
      "Stacking acc 0.9171597633136095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\011305\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "ensemble.fit(train_x, train_y)\n",
    "print('Stacking f1', metrics.f1_score(test_y, ensemble.predict(test_x)))\n",
    "print('Stacking recall', metrics.recall_score(test_y, ensemble.predict(test_x)))\n",
    "print('Stacking acc', metrics.accuracy_score(test_y, ensemble.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b21ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
