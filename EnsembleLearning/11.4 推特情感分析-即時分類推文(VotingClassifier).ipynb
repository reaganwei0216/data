{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T02:28:29.068385Z",
     "iopub.status.busy": "2021-12-09T02:28:29.067885Z",
     "iopub.status.idle": "2021-12-09T02:28:38.71481Z",
     "shell.execute_reply": "2021-12-09T02:28:38.713859Z",
     "shell.execute_reply.started": "2021-12-09T02:28:29.068285Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tweepy==3.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://realpython.com/twitter-bot-python-tweepy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T02:28:38.717077Z",
     "iopub.status.busy": "2021-12-09T02:28:38.716851Z",
     "iopub.status.idle": "2021-12-09T02:28:40.482107Z",
     "shell.execute_reply": "2021-12-09T02:28:40.481344Z",
     "shell.execute_reply.started": "2021-12-09T02:28:38.717052Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation\n",
    "from datetime import datetime, date, timedelta\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import tweepy\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T02:28:40.483331Z",
     "iopub.status.busy": "2021-12-09T02:28:40.483139Z",
     "iopub.status.idle": "2021-12-09T02:28:47.584862Z",
     "shell.execute_reply": "2021-12-09T02:28:47.583938Z",
     "shell.execute_reply.started": "2021-12-09T02:28:40.483308Z"
    }
   },
   "outputs": [],
   "source": [
    "# 讀取資料並指定標籤\n",
    "labels = ['polarity', 'id', 'date', 'query', 'user', 'text']\n",
    "data = pd.read_csv(\"../Data/training.1600000.processed.noemoticon.csv\", \n",
    "                   names=labels,\n",
    "                   encoding='latin-1')\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T02:28:47.586605Z",
     "iopub.status.busy": "2021-12-09T02:28:47.58625Z",
     "iopub.status.idle": "2021-12-09T02:28:47.708356Z",
     "shell.execute_reply": "2021-12-09T02:28:47.707676Z",
     "shell.execute_reply.started": "2021-12-09T02:28:47.586563Z"
    }
   },
   "outputs": [],
   "source": [
    "# 只保留文字內容和極性，將極性改為 0(負面推文)、1(正面推文)\n",
    "data = data[['text', 'polarity']]\n",
    "data.polarity.replace(4, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T02:28:47.710327Z",
     "iopub.status.busy": "2021-12-09T02:28:47.710112Z",
     "iopub.status.idle": "2021-12-09T02:28:47.72006Z",
     "shell.execute_reply": "2021-12-09T02:28:47.719001Z",
     "shell.execute_reply.started": "2021-12-09T02:28:47.710302Z"
    }
   },
   "outputs": [],
   "source": [
    "# 創建一個停用詞列表\n",
    "# from nltk.corpus import stopwords\n",
    "stops = stopwords.words(\"english\")\n",
    "\n",
    "# 添加不帶單引號的停用詞 dont(原先為don't) 加入停用詞\n",
    "no_quotes = []\n",
    "for word in stops:\n",
    "    if \"'\" in word:\n",
    "        no_quotes.append(re.sub(r'\\'', '', word))\n",
    "stops.extend(no_quotes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T02:28:47.72161Z",
     "iopub.status.busy": "2021-12-09T02:28:47.721244Z",
     "iopub.status.idle": "2021-12-09T02:28:47.728097Z",
     "shell.execute_reply": "2021-12-09T02:28:47.727374Z",
     "shell.execute_reply.started": "2021-12-09T02:28:47.721581Z"
    }
   },
   "outputs": [],
   "source": [
    "# 刪除推文中的主題標籤(hashtag)、URL、HTML屬性等\n",
    "def clean_string(string):\n",
    "    # 刪除 HTML 特殊字元\n",
    "    tmp = re.sub(r'\\&\\w*;', '', string)\n",
    "    # 刪除 @user\n",
    "    tmp = re.sub(r'@(\\w+)', '', tmp)\n",
    "    # 刪除鏈結\n",
    "    tmp = re.sub(r'(http|https|ftp)://[a-zA-Z0-9\\\\./]+', '', tmp)\n",
    "    # 轉小寫\n",
    "    tmp = tmp.lower()\n",
    "    # 刪除主題標籤\n",
    "    tmp = re.sub(r'#(\\w+)', '', tmp)\n",
    "    # 刪除重複字元\n",
    "    tmp = re.sub(r'(.)\\1{1,}', r'\\1\\1', tmp)\n",
    "    # 刪除任何不是字母的東西\n",
    "    tmp = re.sub(\"[^a-zA-Z]\", \" \", tmp)\n",
    "    # 刪除少於兩個字元的任何內容\n",
    "    tmp = re.sub(r'\\b\\w{1,2}\\b', '', tmp)\n",
    "    # 刪除多個空格\n",
    "    tmp = re.sub(r'\\s\\s+', ' ', tmp)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 詞幹提取(stemming):將單詞還原為字根 EX:love、loving、loved都視為love\n",
    "# stemmer = PorterStemmer()\n",
    "# print(stemmer.stem('working'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T02:28:47.729501Z",
     "iopub.status.busy": "2021-12-09T02:28:47.729082Z",
     "iopub.status.idle": "2021-12-09T02:28:47.742268Z",
     "shell.execute_reply": "2021-12-09T02:28:47.741457Z",
     "shell.execute_reply.started": "2021-12-09T02:28:47.729471Z"
    }
   },
   "outputs": [],
   "source": [
    "# 刪除所有標點符號以及停用詞，並提取每個單字的詞幹\n",
    "def preprocess(string):\n",
    "#     from nltk.stem import PorterStemmer\n",
    "#     from string import punctuation\n",
    "    stemmer = PorterStemmer()\n",
    "    # 刪除標點符號\n",
    "    removed_punc = ''.join([char for char in string if char not in punctuation])\n",
    "\n",
    "    cleaned = []\n",
    "    # 刪除停用詞\n",
    "    for word in removed_punc.split(' '):\n",
    "        if word not in stops:\n",
    "            cleaned.append(stemmer.stem(word.lower()))\n",
    "    return ' '.join(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T02:28:47.743869Z",
     "iopub.status.busy": "2021-12-09T02:28:47.743327Z",
     "iopub.status.idle": "2021-12-09T02:33:54.352833Z",
     "shell.execute_reply": "2021-12-09T02:33:54.351777Z",
     "shell.execute_reply.started": "2021-12-09T02:28:47.743831Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True) # frac (float)：要抽出的比例，0~1  https://ithelp.ithome.com.tw/articles/10233644\n",
    "data.text = data.text.apply(clean_string)\n",
    "data.text = data.text.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T02:33:54.354679Z",
     "iopub.status.busy": "2021-12-09T02:33:54.354328Z",
     "iopub.status.idle": "2021-12-09T02:38:25.651175Z",
     "shell.execute_reply": "2021-12-09T02:38:25.65006Z",
     "shell.execute_reply.started": "2021-12-09T02:33:54.354638Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用投票法分類器\n",
    "# 使用20,000數值向量大小以及範圍1到3的n-gram \n",
    "train_size = 10000\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# 初始化 TfidfVectorizer 函式\n",
    "tf = TfidfVectorizer(max_features=20000, \n",
    "                     ngram_range=(1, 3),\n",
    "                     stop_words='english')\n",
    "# 將文字資料轉換成數值向量\n",
    "tf.fit(data.text)\n",
    "transformed = tf.transform(data.text)\n",
    "# 將稀疏矩陣轉換成numpy矩陣\n",
    "x_data = transformed[:train_size].toarray() # 將資料轉換成模型可以接收的numpy矩陣資料型別\n",
    "y_data = data.polarity[:train_size].values\n",
    "\n",
    "voting = VotingClassifier([('LR', DecisionTreeClassifier()),\n",
    "                           ('NB', MultinomialNB()),\n",
    "                           ('Ridge', RidgeClassifier())])\n",
    "\n",
    "voting.fit(x_data, y_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T02:38:25.653743Z",
     "iopub.status.busy": "2021-12-09T02:38:25.653276Z",
     "iopub.status.idle": "2021-12-09T02:38:25.666046Z",
     "shell.execute_reply": "2021-12-09T02:38:25.664757Z",
     "shell.execute_reply.started": "2021-12-09T02:38:25.653699Z"
    }
   },
   "outputs": [],
   "source": [
    "api_key = 'tsj4P1P8phL90G2QQF1HkQJFh'\n",
    "api_key_secret = 'kc8X3dglmH1VKjk14KdhoYGTNe7AabvuJ4hi5pwgNvuwklMWit'\n",
    "access_token = '1367899270444154883-aEisBRiV9QQYQcBBIS7xyloddHbJJT'\n",
    "access_token_secret = 'TpaAiMfFcvPBg765tDeQcxNkFm4HK1TOyrK6E1jwGemrd'\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True) # 當請求次數超過上限時會拋出異常，然後退出程序，解法為將參數wait_on_rate_limit_notify設置爲True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T02:38:25.673317Z",
     "iopub.status.busy": "2021-12-09T02:38:25.67251Z",
     "iopub.status.idle": "2021-12-09T02:48:02.709206Z",
     "shell.execute_reply": "2021-12-09T02:48:02.708047Z",
     "shell.execute_reply.started": "2021-12-09T02:38:25.673261Z"
    }
   },
   "outputs": [],
   "source": [
    "# 建立連線，用一個迴圈去抓Twitter上關於美國總統拜登的相關推文\n",
    "# 將抓到的推文套用clean_string()資料清理、preprocess()資料轉換函式，接著使用已經訓練好的模型對推文進行預測\n",
    "\n",
    "prev = [\"\"]\n",
    "while(1):\n",
    "    for tweet in api.search(q=\"Biden\", lang=\"en\", rpp=10, count = 1):\n",
    "        test = [f\"{tweet.text}\"]\n",
    "        if(test[0] != prev[0]):\n",
    "            print(\"Text:\\n\", test[0])\n",
    "            prev = copy.deepcopy(test)\n",
    "            test = pd.DataFrame(test)\n",
    "            test.columns =['text']\n",
    "            test.text = test.text.apply(clean_string)\n",
    "            test.text = test.text.apply(preprocess)\n",
    "            test_transformed = tf.transform(test.text)\n",
    "            test_data = test_transformed.toarray()\n",
    "            print(\"\\nPrediction:\", voting.predict(test_data)[0])\n",
    "            print(\"-------------------------\")\n",
    "            time.sleep(5) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
