{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T07:43:37.901545Z",
     "iopub.status.busy": "2021-12-23T07:43:37.900987Z",
     "iopub.status.idle": "2021-12-23T07:43:38.918901Z",
     "shell.execute_reply": "2021-12-23T07:43:38.917941Z",
     "shell.execute_reply.started": "2021-12-23T07:43:37.901438Z"
    }
   },
   "outputs": [],
   "source": [
    "# 匯入函式庫\n",
    "# from sklearn.base import BaseEstimator\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Stacking():\n",
    "# class Stacking(BaseEstimator):\n",
    "\n",
    "    # 定義函式初始化\n",
    "    def __init__(self, learner_levels):\n",
    "        # 接收基學習器、超學習器、以及堆疊中每一層分別有多少學習器\n",
    "        # 複製學習器++\n",
    "        self.level_sizes = []\n",
    "        self.learners = []\n",
    "        self.learner_levels = learner_levels\n",
    "        for learning_level in self.learner_levels:\n",
    "\n",
    "            self.level_sizes.append(len(learning_level))\n",
    "            level_learners = []\n",
    "            for learner in learning_level:\n",
    "                level_learners.append(deepcopy(learner))\n",
    "            self.learners.append(level_learners)\n",
    "\n",
    "    # fit 函式\n",
    "    # 用第i-1層的基學習器預測值來訓練第i層的基學習器\n",
    "    def fit(self, x, y):\n",
    "        # 第1層基學習器的訓練資料即為原始資料\n",
    "        meta_data = [x]\n",
    "        meta_targets = [y]\n",
    "        for i in range(len(self.learners)):\n",
    "            level_size = self.level_sizes[i]\n",
    "\n",
    "            # 建立第i層預測值的儲存空間\n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "            target_z = np.zeros(len(x))\n",
    "\n",
    "            # 取得第i層訓練資料集\n",
    "            train_x = meta_data[i]\n",
    "            train_y = meta_targets[i]\n",
    "\n",
    "            # 建立交叉驗證\n",
    "            KF = KFold(n_splits=3)\n",
    "            meta_index = 0\n",
    "            for train_indices, test_indices in KF.split(x):\n",
    "                for j in range(len(self.learners[i])):\n",
    "                    # 使用前K-1折訓練第j個基學習器\n",
    "                    learner = self.learners[i][j]\n",
    "                    learner.fit(train_x[train_indices], train_y[train_indices])\n",
    "                    # 使用第K折驗證第j個基學習器\n",
    "                    predictions = learner.predict(train_x[test_indices])\n",
    "                    # 儲存第K折第j個基學習器預測結果\n",
    "                    data_z[j][meta_index:meta_index+len(test_indices)] = predictions\n",
    "\n",
    "                # 儲存第i層基學習器的預測結果\n",
    "                # 作為第i+1層基學習器的訓練資料\n",
    "                target_z[meta_index:meta_index+len(test_indices)] = train_y[test_indices]\n",
    "                meta_index += len(test_indices)\n",
    "\n",
    "            # Add the data and targets to the meta data lists\n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "            meta_targets.append(target_z)\n",
    "\n",
    "\n",
    "            # 使用完整的訓練資料來訓練基學習器\n",
    "            for learner in self.learners[i]:\n",
    "                    learner.fit(train_x, train_y)\n",
    "\n",
    "    # predict 函式\n",
    "    def predict(self, x):\n",
    "\n",
    "        # 儲存每一層的預測\n",
    "        meta_data = [x]\n",
    "        for i in range(len(self.learners)):\n",
    "            level_size = self.level_sizes[i]\n",
    "\n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "\n",
    "            test_x = meta_data[i]\n",
    "\n",
    "            KF = KFold(n_splits=3)\n",
    "            for train_indices, test_indices in KF.split(x):\n",
    "                for j in range(len(self.learners[i])):\n",
    "\n",
    "                    learner = self.learners[i][j]\n",
    "                    predictions = learner.predict(test_x)\n",
    "                    data_z[j] = predictions\n",
    "\n",
    "            # 儲存第i層基學習器的預測結果\n",
    "            # 作為第i+1層基學習器的輸入\n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "\n",
    "        # 傳回預測結果\n",
    "        return meta_data[-1]\n",
    "\n",
    "    # predict_proba 函式\n",
    "    def predict_proba(self, x):\n",
    "\n",
    "        # 儲存每一層的預測\n",
    "        meta_data = [x]\n",
    "        for i in range(len(self.learners)-1):\n",
    "            level_size = self.level_sizes[i]\n",
    "\n",
    "            data_z = np.zeros((level_size, len(x)))\n",
    "\n",
    "            test_x = meta_data[i]\n",
    "\n",
    "            KF = KFold(n_splits=5)\n",
    "            for train_indices, test_indices in KF.split(x):\n",
    "                for j in range(len(self.learners[i])):\n",
    "\n",
    "                    learner = self.learners[i][j]\n",
    "                    predictions = learner.predict(test_x)\n",
    "                    data_z[j] = predictions\n",
    "\n",
    "            # 儲存第i層基學習器的預測結果\n",
    "            # 作為第i+1層基學習器的輸入\n",
    "            data_z = data_z.transpose()\n",
    "            meta_data.append(data_z)\n",
    "\n",
    "        # 傳回預測結果\n",
    "        learner = self.learners[-1][-1]\n",
    "        return learner.predict_proba(meta_data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-23T07:43:38.921734Z",
     "iopub.status.busy": "2021-12-23T07:43:38.921276Z",
     "iopub.status.idle": "2021-12-23T07:43:43.121444Z",
     "shell.execute_reply": "2021-12-23T07:43:43.1205Z",
     "shell.execute_reply.started": "2021-12-23T07:43:38.921686Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- 第 1 部分 ---\n",
    "# 載入函式庫與資料集\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from stacking_classifier import Stacking\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(123456)\n",
    "data = pd.read_csv('../Data/creditcard.csv')\n",
    "data.Time = (data.Time-data.Time.min())/data.Time.std()\n",
    "data.Amount = (data.Amount-data.Amount.mean())/data.Amount.std()\n",
    "\n",
    "# 把資料分為 70% 訓練資料集與 30% 測試資料集\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.drop('Class', axis=1).values, \n",
    "                                                    data.Class.values, \n",
    "                                                    test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T07:43:43.122962Z",
     "iopub.status.busy": "2021-12-23T07:43:43.122703Z",
     "iopub.status.idle": "2021-12-23T07:44:31.070967Z",
     "shell.execute_reply": "2021-12-23T07:44:31.06996Z",
     "shell.execute_reply.started": "2021-12-23T07:43:43.122931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking f1 0.814516129032258\n",
      "Stacking recall 0.7426470588235294\n"
     ]
    }
   ],
   "source": [
    "# --- 第 2 部分 ---\n",
    "# 進行集成\n",
    "base_classifiers = [DecisionTreeClassifier(max_depth = 10),\n",
    "                    GaussianNB(),\n",
    "                    LogisticRegression(solver = 'liblinear')]\n",
    "\n",
    "meta_learners = [LogisticRegression(solver = 'liblinear')]\n",
    "\n",
    "ensemble = Stacking(learner_levels = [base_classifiers,\n",
    "                                      meta_learners])\n",
    "ensemble.fit(x_train, y_train)\n",
    "print('Stacking f1', metrics.f1_score(y_test, ensemble.predict(x_test)))\n",
    "print('Stacking recall', metrics.recall_score(y_test, ensemble.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評估原始訓練資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T07:44:31.074569Z",
     "iopub.status.busy": "2021-12-23T07:44:31.074059Z",
     "iopub.status.idle": "2021-12-23T07:44:48.665458Z",
     "shell.execute_reply": "2021-12-23T07:44:48.664239Z",
     "shell.execute_reply.started": "2021-12-23T07:44:31.074523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking f1 0.8253968253968255\n",
      "Stacking recall 0.7703703703703704\n"
     ]
    }
   ],
   "source": [
    "# --- 第 3 部分 ---\n",
    "# 篩選特徵\n",
    "threshold = 0.1\n",
    "correlations = data.corr()['Class'].drop('Class')\n",
    "fs = list(correlations[(abs(correlations) > threshold)].index.values)\n",
    "fs.append('Class')\n",
    "data = data[fs]\n",
    "\n",
    "x_train_f, x_test_f, y_train_f, y_test_f = train_test_split(data.drop('Class', axis=1).values, \n",
    "                                                            data.Class.values, \n",
    "                                                            test_size=0.3)\n",
    "ensemble = Stacking(learner_levels = [base_classifiers,\n",
    "                                      meta_learners])\n",
    "ensemble.fit(x_train_f, y_train_f)\n",
    "print('Stacking f1', metrics.f1_score(y_test_f, ensemble.predict(x_test_f)))\n",
    "print('Stacking recall', metrics.recall_score(y_test_f, ensemble.predict(x_test_f)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 另添加另外2顆決策樹(最大深度分別為6和7)基學習器，評估原始訓練資料和過濾低相關性的資料集成的效能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T07:44:48.672616Z",
     "iopub.status.busy": "2021-12-23T07:44:48.666968Z",
     "iopub.status.idle": "2021-12-23T07:46:56.010794Z",
     "shell.execute_reply": "2021-12-23T07:46:56.009804Z",
     "shell.execute_reply.started": "2021-12-23T07:44:48.672539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始訓練資料:\n",
      "Stacking f1 0.8455284552845528\n",
      "Stacking recall 0.7647058823529411\n",
      "過濾低相關性的資料:\n",
      "Stacking f1 0.8494208494208493\n",
      "Stacking recall 0.8148148148148148\n"
     ]
    }
   ],
   "source": [
    "# --- 第 4 部分 ---\n",
    "# 增加基學習器\n",
    "base_classifiers = [DecisionTreeClassifier(max_depth = 10),\n",
    "                    DecisionTreeClassifier(max_depth = 7),\n",
    "                    DecisionTreeClassifier(max_depth = 6),\n",
    "                    GaussianNB(),\n",
    "                    LogisticRegression(solver = 'liblinear')]\n",
    "\n",
    "# 原始訓練資料\n",
    "ensemble = Stacking(learner_levels = [base_classifiers,\n",
    "                                      meta_learners])\n",
    "ensemble.fit(x_train, y_train)\n",
    "print('原始訓練資料:')\n",
    "print('Stacking f1', metrics.f1_score(y_test, ensemble.predict(x_test)))\n",
    "print('Stacking recall', metrics.recall_score(y_test, ensemble.predict(x_test)))\n",
    "\n",
    "\n",
    "# 過濾低相關性的資料\n",
    "ensemble = Stacking(learner_levels = [base_classifiers,\n",
    "                                      meta_learners])\n",
    "ensemble.fit(x_train_f, y_train_f)\n",
    "print('過濾低相關性的資料:')\n",
    "print('Stacking f1', metrics.f1_score(y_test_f, ensemble.predict(x_test_f)))\n",
    "print('Stacking recall', metrics.recall_score(y_test_f, ensemble.predict(x_test_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 除另添加另外2顆決策樹(最大深度分別為6和7)，另多堆疊一層基學習器(包含深度為2的決策樹和一個線性資源向量機)，評估原始訓練資料和過濾低相關性的資料集成的效能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-23T07:46:56.01296Z",
     "iopub.status.busy": "2021-12-23T07:46:56.012356Z",
     "iopub.status.idle": "2021-12-23T07:49:20.889Z",
     "shell.execute_reply": "2021-12-23T07:49:20.888074Z",
     "shell.execute_reply.started": "2021-12-23T07:46:56.01291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始訓練資料:\n",
      "Stacking f1 0.8489795918367347\n",
      "Stacking recall 0.7647058823529411\n",
      "過濾低相關性的資料:\n",
      "Stacking f1 0.840466926070039\n",
      "Stacking recall 0.8\n"
     ]
    }
   ],
   "source": [
    "# --- 第 5 部分 ---\n",
    "# 增加一層\n",
    "base_classifiers = [DecisionTreeClassifier(max_depth = 10),\n",
    "                    DecisionTreeClassifier(max_depth = 7),\n",
    "                    DecisionTreeClassifier(max_depth = 6),\n",
    "                    GaussianNB(),\n",
    "                    LogisticRegression(solver = 'liblinear')]\n",
    "\n",
    "second_learners = [DecisionTreeClassifier(max_depth = 2),\n",
    "                   LinearSVC()]\n",
    "\n",
    "# 原始訓練資料\n",
    "ensemble = Stacking(learner_levels = [base_classifiers,\n",
    "                                      second_learners,\n",
    "                                      meta_learners])\n",
    "ensemble.fit(x_train, y_train)\n",
    "print('原始訓練資料:')\n",
    "print('Stacking f1', metrics.f1_score(y_test, ensemble.predict(x_test)))\n",
    "print('Stacking recall', metrics.recall_score(y_test, ensemble.predict(x_test)))\n",
    "\n",
    "# 過濾低相關性的資料\n",
    "ensemble = Stacking(learner_levels = [base_classifiers,\n",
    "                                      second_learners,\n",
    "                                      meta_learners])\n",
    "ensemble.fit(x_train_f, y_train_f)\n",
    "print('過濾低相關性的資料:')\n",
    "print('Stacking f1', metrics.f1_score(y_test_f, ensemble.predict(x_test_f)))\n",
    "print('Stacking recall', metrics.recall_score(y_test_f, ensemble.predict(x_test_f)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
