{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 20 - PTT Graph\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "* [PTT.cc](#ptt)\n",
    "* [Import data to MongoDB](#import_mongo)\n",
    "* [Load data from MongoDB](#load_data_from_mongodb)\n",
    "* [Create Keyword Node](#create_keyword)\n",
    "* [Create Post Node](#create_post_node)\n",
    "* [Create User Node](#create_user_node)\n",
    "* [Relationship of PTTPost keywords and post](#relationship_ptt_keyword_POST)\n",
    "* [Relationship of PTTPost and User](#relationship_post_user)\n",
    "* [Relationship of PTTPost keywords and comment](#)\n",
    "* [Create comment Node](#create_comment_node)\n",
    "* [Relationship of Comment and Post](#relationship_comment_post)\n",
    "* [Relationship of Comment and User](#relationship_comment_user)\n",
    "* [Import to Neo4j](#import_neo4j)\n",
    "* [Cypher query](#cypher)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ptt\"></a>\n",
    "## PTT.cc\n",
    "\n",
    "Ptt，中文名批踢踢實業坊。但知道這個站名`由來`的人不太多，還曾有人覺得Ptt是「怕太太」的意思。\n",
    "\n",
    "Ptt名稱來自創站者杜奕瑾（ID:Ptt）本人帳號的名稱，根據他在2010年的一場演講中的說法，該名稱的由來是「Panda Tu」一稱呼，Panda即熊貓，他自述因為在大學時常睡眠不足有黑眼圈，很像熊貓，Tu是他的姓「杜」的拼音（護照上的名字），因此取P和T兩開頭字母，然後覺得有兩個T感覺唸起來比較好聽，於是就成為Ptt。\n",
    "\n",
    "同樣據杜奕瑾所說，後來Ptt作為站名，可以進一步衍伸的意義則包括「P」是「批判」，「T」是「踢爆」，代表ptt具有批評懷疑社會既有觀念的精神。另一種衍伸的意義是「Professional　Techonolgy　Temple」（專業科技殿堂）（因此並非一開始就是這三個字的縮寫）\n",
    "\n",
    "<img src=\"images/ptt_incoming.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import_mongo\"></a>\n",
    "## Import data to MongoDB\n",
    "\n",
    "- ./data/mongo/ptt/\n",
    "\n",
    "```\n",
    "mongorestore -h 127.0.0.1 --port 27017 --db ptt ptt --drop\n",
    "```\n",
    "\n",
    "<img src=\"images/restore_ptt_mongodb_done.png\">\n",
    "\n",
    "<img src=\"images/robomongo_ptt.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import ast\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlencode\n",
    "from datetime import (datetime as dt, timedelta as td)\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from urllib.parse import quote, unquote\n",
    "from pymongo import MongoClient\n",
    "from pymongo import UpdateOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyword_id(keyword):\n",
    "    return hashtag_keyword_map[str(keyword).strip()]\n",
    "\n",
    "def add_quote(keyword):\n",
    "    return '\"'+str(keyword).replace('\\n', ' ').replace('\\r', ' ').strip()+'\"'\n",
    "\n",
    "def replace_double_quote(s):\n",
    "    return str(s).strip().replace('\"',\"'\")\n",
    "\n",
    "def if_in_list(item, target_list):\n",
    "    if item not in target_list:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def extract_ptt_post_id(url):\n",
    "    return url.split('/')[-1:][0].replace('.html','')\n",
    "\n",
    "def trim_locale(locale):\n",
    "    return locale.replace('(','').replace(')','')\n",
    "\n",
    "def extract_hashtag(content):\n",
    "    hashtags = []\n",
    "    if type(content)==float:\n",
    "        return \"\"\n",
    "    if '#' in content:\n",
    "        for h in content.split('#')[1:]:\n",
    "            hashtags.append('#'+h.split(' ')[0].replace('\\n','').replace('、','').strip())\n",
    "    return \"/\".join(hashtags) if hashtags else \"\"\n",
    "\n",
    "def extract_mention(content):\n",
    "    mentions = []\n",
    "    if type(content)==float:\n",
    "        return \"\"\n",
    "    if '@' in content:\n",
    "        for h in content.split('@')[1:]:\n",
    "            mentions.append('@'+h.split(' ')[0].replace('\\n','').replace('、','').strip())\n",
    "    return \"/\".join(mentions) if mentions else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\princ\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.924 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "Building prefix dict from D:\\Programming\\Python\\Neo4j\\課程\\dict\\dict.big.txt ...\n",
      "Loading model from cache C:\\Users\\princ\\AppData\\Local\\Temp\\jieba.u2119b7327cb8dafa65534ff0e37256b6.cache\n",
      "Loading model cost 1.424 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "\n",
    "jieba.initialize()\n",
    "jieba.set_dictionary(\"./dict/dict.big.txt\")\n",
    "jieba.load_userdict('./dict/mydic.txt')\n",
    "\n",
    "wantWordList = set()\n",
    "with open('./dict/mydic.txt', 'r', encoding=\"utf8\") as file:\n",
    "    wantWordList = file.readlines()\n",
    "    wantWordList = [wantword.strip('\\n').replace('\\ufeff','').strip().split(' ')[0] for wantword in wantWordList]\n",
    "\n",
    "stopwords = set()\n",
    "with open('./dict/stopwords.txt', 'r', encoding=\"utf8\") as file:\n",
    "    stopwords = file.readlines()\n",
    "    stopwords = [stopword.strip('\\n').strip() for stopword in stopwords]\n",
    "except_file = open(\"./dict/hippo_exception_word.txt\", encoding='utf-8')\n",
    "exception = except_file.read().split(',')\n",
    "exception.append(\" \")\n",
    "\n",
    "punct = set(u''':!),.:;?]}$¢'\"、。〉》」』】〕〗〞︰︱︳﹐､﹒﹔﹕﹖﹗﹚﹜﹞！），．：；？｜｝︴︶︸︺︼︾﹀﹂﹄﹏､～￠々‖•·ˇˉ―--′’”([{£¥'\"‵〈《「『【〔〖（［｛￡￥〝︵︷︹︻︽︿﹁﹃﹙﹛﹝（｛“‘-—_…''')\n",
    "punct |= set(exception)\n",
    "punct = list(punct)\n",
    "stopwords = set(stopwords+punct)\n",
    "\n",
    "names = set()\n",
    "with open('./dict/name.txt', 'r', encoding=\"utf-8\") as file:\n",
    "    names= file.readlines()\n",
    "    names = [name.strip('\\n').strip() for name in names]\n",
    "\n",
    "def segmentWord(text):\n",
    "    words = [word for word in jieba.cut(text, cut_all=False) if len(word.strip())>1 and (word not in stopwords)  ]\n",
    "    return \"/\".join(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_URI = 'mongodb://127.0.0.1:27017'\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "database_name = 'ptt'\n",
    "collection_name = 'Gossiping'\n",
    "db = client[database_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load_data_from_mongodb\"></a>\n",
    "## Load data from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.strptime(\"2020-11-12 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "end = datetime.datetime.strptime(\"2020-11-13 23:59:59\", \"%Y-%m-%d %H:%M:%S\")\n",
    "result = list(db[collection_name].find({ \"date\":{'$gt': start, '$lt': end} }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>board</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>ip</th>\n",
       "      <th>locale</th>\n",
       "      <th>comments</th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "      <th>updatetime</th>\n",
       "      <th>postId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>Gossiping</td>\n",
       "      <td>[問卦] 我朋友當儀隊被川普老婆挽著有反映怎辦?</td>\n",
       "      <td>shoga</td>\n",
       "      <td>\\n\\n我朋友美國大鵰當美軍儀隊啦\\n碰到總統來主持退伍軍人紀念儀式\\n現場下雨要我朋友幫第...</td>\n",
       "      <td>2020-11-12 21:58:55</td>\n",
       "      <td>123.194.160.91</td>\n",
       "      <td>臺灣</td>\n",
       "      <td>[{'user': 'A80211ab', 'content': ': 要是我也會有反應 超...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1605189538....</td>\n",
       "      <td>2020-11-16 10:47:13.158</td>\n",
       "      <td>M.1605189538.A.8A8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          board                     title author  \\\n",
       "2037  Gossiping  [問卦] 我朋友當儀隊被川普老婆挽著有反映怎辦?  shoga   \n",
       "\n",
       "                                                content                date  \\\n",
       "2037  \\n\\n我朋友美國大鵰當美軍儀隊啦\\n碰到總統來主持退伍軍人紀念儀式\\n現場下雨要我朋友幫第... 2020-11-12 21:58:55   \n",
       "\n",
       "                  ip locale  \\\n",
       "2037  123.194.160.91     臺灣   \n",
       "\n",
       "                                               comments  score  \\\n",
       "2037  [{'user': 'A80211ab', 'content': ': 要是我也會有反應 超...      2   \n",
       "\n",
       "                                                    url  \\\n",
       "2037  https://www.ptt.cc/bbs/Gossiping/M.1605189538....   \n",
       "\n",
       "                  updatetime              postId  \n",
       "2037 2020-11-16 10:47:13.158  M.1605189538.A.8A8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result)\n",
    "if '_id' in df.columns:\n",
    "    del df['_id']\n",
    "df.fillna('', inplace=True)\n",
    "df['postId'] = df['url'].apply(lambda x:extract_ptt_post_id(x))\n",
    "df['locale'] = df['locale'].apply(lambda x:trim_locale(x))\n",
    "df['author'] = df['author'].apply(lambda x:str(x).strip())\n",
    "df = df.replace(np.nan, '', regex=True)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_post_node\"></a>\n",
    "## Create Post Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4023\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTTPost:ID</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>ip</th>\n",
       "      <th>locale</th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "      <th>board</th>\n",
       "      <th>:LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>M.1605148480.A.B57</td>\n",
       "      <td>\"Re: [新聞] 高市議會通過萊劑零檢出 陳其邁：盼中央\"</td>\n",
       "      <td>\"weakerman\"</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>2020-11-12 10:34:37</td>\n",
       "      <td>114.47.85.248</td>\n",
       "      <td>臺灣</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1605148480....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>PTTPost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PTTPost:ID                           title       author content  \\\n",
       "3497  M.1605148480.A.B57  \"Re: [新聞] 高市議會通過萊劑零檢出 陳其邁：盼中央\"  \"weakerman\"      \"\"   \n",
       "\n",
       "                    date             ip locale  score  \\\n",
       "3497 2020-11-12 10:34:37  114.47.85.248     臺灣      2   \n",
       "\n",
       "                                                    url      board   :LABEL  \n",
       "3497  https://www.ptt.cc/bbs/Gossiping/M.1605148480....  Gossiping  PTTPost  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptt_post_nodes = df[['postId','title','author','content','date','ip','locale','score','url','board']].copy()\n",
    "ptt_post_nodes[\":LABEL\"] = \"PTTPost\"\n",
    "ptt_post_nodes = ptt_post_nodes.rename(columns={'postId': 'PTTPost:ID'})\n",
    "ptt_post_nodes = ptt_post_nodes.drop_duplicates(subset='PTTPost:ID', keep=\"first\")\n",
    "ptt_post_nodes['keywords'] = list(map(segmentWord, ptt_post_nodes['content']+ptt_post_nodes['title']))\n",
    "ptt_post_nodes[\"author\"] = ptt_post_nodes[\"author\"].apply(lambda x : replace_double_quote(x))\n",
    "ptt_post_nodes[\"author\"] = ptt_post_nodes[\"author\"].apply(lambda x : add_quote(x))\n",
    "ptt_post_nodes[\"content\"] = ptt_post_nodes[\"content\"].apply(lambda x : replace_double_quote(x))\n",
    "ptt_post_nodes[\"content\"] = ptt_post_nodes[\"content\"].apply(lambda x : add_quote(x))\n",
    "ptt_post_nodes[\"title\"] = ptt_post_nodes[\"title\"].apply(lambda x : replace_double_quote(x))\n",
    "ptt_post_nodes[\"title\"] = ptt_post_nodes[\"title\"].apply(lambda x : add_quote(x))\n",
    "ptt_post_nodes[\"content\"] = ptt_post_nodes[\"content\"].apply(lambda x:str(x).replace('\\n',' ').strip())\n",
    "\n",
    "if ptt_post_nodes.shape[0]>0:\n",
    "    ptt_post_nodes_opt = ptt_post_nodes[[\"PTTPost:ID\",\"title\",\"author\",\"content\",\"date\",\"ip\",\"locale\",\"score\",\"url\",\"board\",\":LABEL\"]]\n",
    "else:\n",
    "    ptt_post_nodes_opt = pd.DataFrame(columns=[\"PTTPost:ID\",\"title\",\"author\",\"content\",\"date\",\"ip\",\"locale\",\"score\",\"url\",\"board\",\":LABEL\"])\n",
    "ptt_post_nodes_opt.to_csv('csv/ptt/ptt_post_nodes.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "print(ptt_post_nodes.shape[0])\n",
    "ptt_post_nodes_opt.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_user_node\"></a>\n",
    "## Create Comment Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postId</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>commmentId</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117169</th>\n",
       "      <td>M.1605150059.A.B42</td>\n",
       "      <td>susanna026</td>\n",
       "      <td>覺得 口罩管成這樣 要進黑心瘦肉精豬肉？</td>\n",
       "      <td>2020-11-12 13:17:00</td>\n",
       "      <td>CMT10117169</td>\n",
       "      <td>口罩/要進/瘦肉精/豬肉/管成/黑心</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    postId        user               comment  \\\n",
       "117169  M.1605150059.A.B42  susanna026  覺得 口罩管成這樣 要進黑心瘦肉精豬肉？   \n",
       "\n",
       "                       date   commmentId            keywords  \n",
       "117169  2020-11-12 13:17:00  CMT10117169  口罩/要進/瘦肉精/豬肉/管成/黑心  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_comment = 10000000\n",
    "commentCountList = []\n",
    "commentList = []\n",
    "for index, row in df[df['comments'].str.len() > 0].iterrows():\n",
    "    try:\n",
    "        for x in row['comments']:\n",
    "            if len(x['content'].replace(':','').strip())>0:\n",
    "                year = str(row['date']).split('-')[0]\n",
    "                date_time = x['time'].replace('/','-')\n",
    "                comment_date = year+'-'+date_time+':00'\n",
    "                comment_content = x['content'].replace(':','').strip()\n",
    "                commentList.append({\"postId\":row['postId'],\"user\":x['user'].strip(),\"comment\":comment_content, \"date\":comment_date})\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "df_ptt_comment = pd.DataFrame(commentList)\n",
    "df_ptt_comment['commmentId'] = df_ptt_comment.index +cnt_comment\n",
    "df_ptt_comment['commmentId'] = df_ptt_comment['commmentId'].apply(lambda x:\"CMT\"+str(x))\n",
    "df_ptt_comment['keywords'] = list(map(segmentWord, df_ptt_comment['comment']))\n",
    "print(df_ptt_comment.shape[0])\n",
    "df_ptt_comment.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_user = set(list(df['author'])+list(df_ptt_comment['user']))\n",
    "df_user = pd.DataFrame(list_user, columns={\"user\"})\n",
    "df_user = df_user.drop_duplicates(subset='user', keep=\"first\")\n",
    "bag_username_list = []\n",
    "user_id_map = {}\n",
    "cnt_user = 100000000\n",
    "for index, row in df_user.iterrows():\n",
    "    for user in row['user'].strip().split(','):\n",
    "        if user not in bag_username_list:\n",
    "            cnt_user = cnt_user+1\n",
    "            cnt_user_code = \"CU\"+str(cnt_user)\n",
    "            user_id_map[user] = cnt_user_code\n",
    "            bag_username_list.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23230\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTTUser:ID</th>\n",
       "      <th>username</th>\n",
       "      <th>:LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CU100000001</td>\n",
       "      <td>\"nolander\"</td>\n",
       "      <td>PTTUser</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PTTUser:ID    username   :LABEL\n",
       "0  CU100000001  \"nolander\"  PTTUser"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptt_user_nodes = df_user[['user']].copy()\n",
    "ptt_user_nodes = ptt_user_nodes.rename(columns={'user': 'username'})\n",
    "ptt_user_nodes[\"PTTUser:ID\"] = ptt_user_nodes[\"username\"].map(user_id_map)\n",
    "ptt_user_nodes[\":LABEL\"] = \"PTTUser\"\n",
    "ptt_user_nodes = ptt_user_nodes[[\"PTTUser:ID\",\"username\",\":LABEL\"]]\n",
    "ptt_user_nodes = ptt_user_nodes.drop_duplicates(subset='PTTUser:ID', keep=\"first\")\n",
    "ptt_user_nodes[\"username\"] = ptt_user_nodes[\"username\"].apply(lambda x : replace_double_quote(x))\n",
    "ptt_user_nodes[\"username\"] = ptt_user_nodes[\"username\"].apply(lambda x : add_quote(x))\n",
    "ptt_user_nodes.to_csv('csv/ptt/ptt_user_nodes.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "print(ptt_user_nodes.shape[0])\n",
    "ptt_user_nodes.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_keyword\"></a>\n",
    "## Create Keyword Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>但謝/死人型/橋頭/里長/權利/討論/姊弟/周遭/褫奪公權/署名/致電/友人/得易科/今年/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>霍萱側/甜美/粉色/一轉/Iris/人字奶/賣萌/車頭燈/至今/誠意/IG/朝聖/內褲/豆子...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>心慧/蓓今/許可/分別/根本無法/30%/政策/表示/制度/至今/巨資/強調/市長/哲在/二...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS/放在/冰會/Asus/on/X00QD/問卦/去年/家樂福/my/夏天/常溫/Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>可惜/實力派/on/Sent/SM/唱個/JPTT/唱歌/一堆/相關/my/興趣/好像/接班...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            keywords\n",
       "0  但謝/死人型/橋頭/里長/權利/討論/姊弟/周遭/褫奪公權/署名/致電/友人/得易科/今年/...\n",
       "1  霍萱側/甜美/粉色/一轉/Iris/人字奶/賣萌/車頭燈/至今/誠意/IG/朝聖/內褲/豆子...\n",
       "2  心慧/蓓今/許可/分別/根本無法/30%/政策/表示/制度/至今/巨資/強調/市長/哲在/二...\n",
       "3  ASUS/放在/冰會/Asus/on/X00QD/問卦/去年/家樂福/my/夏天/常溫/Se...\n",
       "4  可惜/實力派/on/Sent/SM/唱個/JPTT/唱歌/一堆/相關/my/興趣/好像/接班..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keywords'] = list(map(segmentWord, df['title']+df['content']))\n",
    "df_ptt_comment.fillna('', inplace=True)\n",
    "df_ptt_comment['keywords'] = list(map(segmentWord, df_ptt_comment['comment']))\n",
    "df_keyword = pd.DataFrame(list(df['keywords'])+list(df_ptt_comment['keywords']), columns=['keywords'])\n",
    "df_keyword.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword:ID</th>\n",
       "      <th>keyword</th>\n",
       "      <th>:LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39940</th>\n",
       "      <td>K100039941</td>\n",
       "      <td>\"山線\"</td>\n",
       "      <td>Keywords</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Keyword:ID keyword    :LABEL\n",
       "39940  K100039941    \"山線\"  Keywords"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_keyword_list = []\n",
    "global_bag_keyword_list = []\n",
    "keyword_id_map = {}\n",
    "cnt_keyword = 100_000_000\n",
    "for index, row in df_keyword.iterrows():\n",
    "    for keyword in row['keywords'].split('/'):\n",
    "        if keyword.strip() not in global_bag_keyword_list:\n",
    "            cnt_keyword = cnt_keyword+1\n",
    "            cnt_keyword_code = \"K\"+str(cnt_keyword)\n",
    "            keyword_id_map[keyword] = cnt_keyword_code\n",
    "            bag_keyword_list.append({\"id\":cnt_keyword_code, \"keyword\":keyword})\n",
    "            global_bag_keyword_list.append(keyword)\n",
    "\n",
    "if global_bag_keyword_list:\n",
    "    # Create keyword nodes\n",
    "    all_keyword_nodes = pd.DataFrame(bag_keyword_list)\n",
    "    all_keyword_nodes = all_keyword_nodes.rename(columns={'id':'Keyword:ID'})\n",
    "    all_keyword_nodes[\":LABEL\"] = \"Keywords\"\n",
    "    all_keyword_nodes[\"keyword\"] = all_keyword_nodes[\"keyword\"].apply(lambda x : replace_double_quote(x))\n",
    "    all_keyword_nodes[\"keyword\"] = all_keyword_nodes[\"keyword\"].apply(lambda x: add_quote(x))\n",
    "    all_keyword_nodes.to_csv(f'csv/ptt/post_keyword_nodes.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "else:\n",
    "    # Create empty keyword nodes\n",
    "    keyword_id_map = {}\n",
    "    all_keyword_nodes = pd.DataFrame(columns=['Keyword:ID', 'keyword', ':LABEL'])\n",
    "    all_keyword_nodes.to_csv(f'csv/ptt/post_keyword_nodes.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "all_keyword_nodes.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"relationship_ptt_keyword_POST\"></a>\n",
    "## Relationship of PTTPost keywords and post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130381\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:START_ID</th>\n",
       "      <th>keyword</th>\n",
       "      <th>:END_ID</th>\n",
       "      <th>:TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>K100000359</td>\n",
       "      <td>\"my\"</td>\n",
       "      <td>M.1605275683.A.A58</td>\n",
       "      <td>RELATED_TO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       :START_ID keyword             :END_ID       :TYPE\n",
       "5768  K100000359    \"my\"  M.1605275683.A.A58  RELATED_TO"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_id_list = list(ptt_post_nodes['PTTPost:ID'])\n",
    "Ptt_keyword_list = []\n",
    "for index, row in ptt_post_nodes[ptt_post_nodes['keywords']!=''].iterrows():\n",
    "    for keyword in row['keywords'].replace('\\n',' ').strip().split('/'):\n",
    "        Ptt_keyword_list.append({\"keyword\":keyword, \"postId\":row['PTTPost:ID']})\n",
    "Ptt_keyword_nodes = pd.DataFrame(Ptt_keyword_list)\n",
    "Ptt_keyword_relation = Ptt_keyword_nodes[['keyword','postId']]\n",
    "Ptt_keyword_relation = Ptt_keyword_relation.rename(columns={'keyword': 'keyword',\n",
    "                                                            'postId': ':END_ID'})\n",
    "Ptt_keyword_relation[\":START_ID\"] =  Ptt_keyword_relation[\"keyword\"].map(keyword_id_map)\n",
    "Ptt_keyword_relation[\":END_ID\"] = Ptt_keyword_relation[\":END_ID\"].apply(lambda x:str(x))\n",
    "Ptt_keyword_relation['in_list'] = Ptt_keyword_relation[':END_ID'].apply(lambda x:if_in_list(x, to_id_list))\n",
    "Ptt_keyword_relation = Ptt_keyword_relation[Ptt_keyword_relation['in_list']==1]\n",
    "del Ptt_keyword_relation['in_list']\n",
    "Ptt_keyword_relation[':TYPE'] = 'RELATED_TO'\n",
    "Ptt_keyword_relation[\"keyword\"] = Ptt_keyword_relation[\"keyword\"].apply(lambda x : replace_double_quote(x))\n",
    "Ptt_keyword_relation[\"keyword\"] = Ptt_keyword_relation[\"keyword\"].apply(lambda x : add_quote(x))\n",
    "Ptt_keyword_relation = Ptt_keyword_relation[[\":START_ID\",\"keyword\",\":END_ID\",\":TYPE\"]]\n",
    "Ptt_keyword_relation.to_csv('csv/ptt/ptt_post_keyword_rel.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "print(Ptt_keyword_relation.shape[0])\n",
    "Ptt_keyword_relation.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"relationship_ptt_keyword_COMMENT\"></a>\n",
    "## Relationship of PTTPost keywords and comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_id_list = list(df_ptt_comment['commmentId'])\n",
    "Ptt_keyword_list = []\n",
    "for index, row in df_ptt_comment[df_ptt_comment['keywords']!=''].iterrows():\n",
    "    for keyword in row['keywords'].replace('\\n',' ').strip().split('/'):\n",
    "        Ptt_keyword_list.append({\"keyword\":keyword, \"commmentId\":row['commmentId']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:START_ID</th>\n",
       "      <th>keyword</th>\n",
       "      <th>:END_ID</th>\n",
       "      <th>:TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357737</th>\n",
       "      <td>K100011364</td>\n",
       "      <td>\"自律\"</td>\n",
       "      <td>CMT10112949</td>\n",
       "      <td>RELATED_TO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         :START_ID keyword      :END_ID       :TYPE\n",
       "357737  K100011364    \"自律\"  CMT10112949  RELATED_TO"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ptt_keyword_nodes = pd.DataFrame(Ptt_keyword_list)\n",
    "Ptt_keyword_relation = Ptt_keyword_nodes[['keyword','commmentId']]\n",
    "Ptt_keyword_relation = Ptt_keyword_relation.rename(columns={'keyword': 'keyword',\n",
    "                                                            'commmentId': ':END_ID'})\n",
    "Ptt_keyword_relation[\":START_ID\"] =  Ptt_keyword_relation[\"keyword\"].map(keyword_id_map)\n",
    "Ptt_keyword_relation[\":END_ID\"] = Ptt_keyword_relation[\":END_ID\"].apply(lambda x:str(x))\n",
    "Ptt_keyword_relation['in_list'] = Ptt_keyword_relation[':END_ID'].apply(lambda x:if_in_list(x, to_id_list))\n",
    "Ptt_keyword_relation = Ptt_keyword_relation[Ptt_keyword_relation['in_list']==1]\n",
    "del Ptt_keyword_relation['in_list']\n",
    "Ptt_keyword_relation[':TYPE'] = 'RELATED_TO'\n",
    "Ptt_keyword_relation[\"keyword\"] = Ptt_keyword_relation[\"keyword\"].apply(lambda x : replace_double_quote(x))\n",
    "Ptt_keyword_relation[\"keyword\"] = Ptt_keyword_relation[\"keyword\"].apply(lambda x : add_quote(x))\n",
    "Ptt_keyword_relation = Ptt_keyword_relation[[\":START_ID\",\"keyword\",\":END_ID\",\":TYPE\"]]\n",
    "Ptt_keyword_relation.to_csv('csv/ptt/ptt_comment_keyword_rel.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "print(Ptt_keyword_relation.shape[0])\n",
    "Ptt_keyword_relation.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"relationship_post_user\"></a>\n",
    "## Relationship of PTTPost and User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4023\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:START_ID</th>\n",
       "      <th>username</th>\n",
       "      <th>title</th>\n",
       "      <th>:END_ID</th>\n",
       "      <th>:TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>CU100018808</td>\n",
       "      <td>\"lelingzi\"</td>\n",
       "      <td>\"[問卦] 唸文組有什麼壓力嗎？\"</td>\n",
       "      <td>M.1605275511.A.0DE</td>\n",
       "      <td>POSTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       :START_ID    username              title             :END_ID  :TYPE\n",
       "184  CU100018808  \"lelingzi\"  \"[問卦] 唸文組有什麼壓力嗎？\"  M.1605275511.A.0DE  POSTS"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_id_list = list(ptt_post_nodes['PTTPost:ID'])\n",
    "ptt_user_post_relation = df[['author','title','postId']]\n",
    "ptt_user_post_relation[\":START_ID\"] = ptt_user_post_relation[\"author\"].map(user_id_map)\n",
    "ptt_user_post_relation = ptt_user_post_relation.rename(columns={'author': 'username',\n",
    "                                                                'postId': ':END_ID'})\n",
    "ptt_user_post_relation['in_list'] = ptt_user_post_relation[':END_ID'].apply(lambda x:if_in_list(x, to_id_list))\n",
    "ptt_user_post_relation = ptt_user_post_relation[ptt_user_post_relation['in_list']==1]\n",
    "del ptt_user_post_relation['in_list']\n",
    "ptt_user_post_relation[':TYPE'] = 'POSTS'\n",
    "# ptt_user_post_relation[':START_ID'] = ptt_user_post_relation[':START_ID'].apply(np.int64)\n",
    "ptt_user_post_relation[':START_ID'] = ptt_user_post_relation[':START_ID'].apply(lambda x:str(x))\n",
    "ptt_user_post_relation = ptt_user_post_relation[[\":START_ID\",\"username\",\"title\",\":END_ID\",\":TYPE\"]]\n",
    "ptt_user_post_relation[\"username\"] = ptt_user_post_relation[\"username\"].apply(lambda x : replace_double_quote(x))\n",
    "ptt_user_post_relation[\"username\"] = ptt_user_post_relation[\"username\"].apply(lambda x : add_quote(x))\n",
    "ptt_user_post_relation[\"title\"] = ptt_user_post_relation[\"title\"].apply(lambda x : replace_double_quote(x))\n",
    "ptt_user_post_relation[\"title\"] = ptt_user_post_relation[\"title\"].apply(lambda x : add_quote(x))\n",
    "ptt_user_post_relation.to_csv('csv/ptt/ptt_user_post_rel.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "print(ptt_user_post_relation.shape[0])\n",
    "ptt_user_post_relation.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_comment_node\"></a>\n",
    "## Create comment Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postId</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>commmentId</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38111</th>\n",
       "      <td>M.1605237144.A.C6E</td>\n",
       "      <td>scottandk</td>\n",
       "      <td>認真說，很會善用自己優勢，但機體(腦袋)受限</td>\n",
       "      <td>2020-11-13 11:40:00</td>\n",
       "      <td>CMT10038111</td>\n",
       "      <td>很會/機體/善用/受限/認真/優勢/腦袋</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   postId       user                 comment  \\\n",
       "38111  M.1605237144.A.C6E  scottandk  認真說，很會善用自己優勢，但機體(腦袋)受限   \n",
       "\n",
       "                      date   commmentId              keywords  \n",
       "38111  2020-11-13 11:40:00  CMT10038111  很會/機體/善用/受限/認真/優勢/腦袋  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ptt_comment.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTTComment:ID</th>\n",
       "      <th>comment</th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>:LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44939</th>\n",
       "      <td>CMT10044939</td>\n",
       "      <td>\"4歲年輕人？滿口幹話\"</td>\n",
       "      <td>\"ShadeSea\"</td>\n",
       "      <td>2020-11-13 09:52:00</td>\n",
       "      <td>PTTComment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PTTComment:ID       comment        user                 date      :LABEL\n",
       "44939   CMT10044939  \"4歲年輕人？滿口幹話\"  \"ShadeSea\"  2020-11-13 09:52:00  PTTComment"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptt_comment_nodes = df_ptt_comment[['commmentId','comment','user','date']].copy()\n",
    "\n",
    "ptt_comment_nodes[\":LABEL\"] = \"PTTComment\"\n",
    "ptt_comment_nodes = ptt_comment_nodes.rename(columns={'commmentId': 'PTTComment:ID'})\n",
    "ptt_comment_nodes = ptt_comment_nodes.drop_duplicates(subset='PTTComment:ID', keep=\"first\")\n",
    "\n",
    "ptt_comment_nodes[\"user\"] = ptt_comment_nodes[\"user\"].apply(lambda x : replace_double_quote(x))\n",
    "ptt_comment_nodes[\"user\"] = ptt_comment_nodes[\"user\"].apply(lambda x : add_quote(x))\n",
    "ptt_comment_nodes[\"comment\"] = ptt_comment_nodes[\"comment\"].apply(lambda x : replace_double_quote(x))\n",
    "ptt_comment_nodes[\"comment\"] = ptt_comment_nodes[\"comment\"].apply(lambda x : add_quote(x))\n",
    "ptt_comment_nodes.to_csv('csv/ptt/ptt_comment_nodes.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "print(ptt_comment_nodes.shape[0])\n",
    "ptt_comment_nodes.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"relationship_comment_post\"></a>\n",
    "## Relationship of Comment and Post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138875\n",
      "138875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postId</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>commmentId</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>M.1605249729.A.876</td>\n",
       "      <td>daruq</td>\n",
       "      <td>種九層塔</td>\n",
       "      <td>2020-11-13 16:25:00</td>\n",
       "      <td>CMT10023812</td>\n",
       "      <td>九層</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   postId   user comment                 date   commmentId  \\\n",
       "23812  M.1605249729.A.876  daruq    種九層塔  2020-11-13 16:25:00  CMT10023812   \n",
       "\n",
       "      keywords  \n",
       "23812       九層  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_ptt_comment.shape[0])\n",
    "df_ptt_comment2 = df_ptt_comment[df_ptt_comment['user'].notna()]\n",
    "print(df_ptt_comment2.shape[0])\n",
    "df_ptt_comment2.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTTPost:ID</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>ip</th>\n",
       "      <th>locale</th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "      <th>board</th>\n",
       "      <th>:LABEL</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>M.1605148417.A.88C</td>\n",
       "      <td>\"[問卦] 有沒有 Overwatch 還死掉的八卦\"</td>\n",
       "      <td>\"mossdevin\"</td>\n",
       "      <td>\"今天早上 youtube 大家都知道掛掉了 炒得沸沸揚揚  結果有人貼出一個偵測網站\"</td>\n",
       "      <td>2020-11-12 10:33:34</td>\n",
       "      <td>180.217.87.229</td>\n",
       "      <td>臺灣</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.ptt.cc/bbs/Gossiping/M.1605148417....</td>\n",
       "      <td>Gossiping</td>\n",
       "      <td>PTTPost</td>\n",
       "      <td>貼出/掛掉/youtube/炒得/有人/Overwatch/死掉/問卦/八卦/偵測/早上/網...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PTTPost:ID                        title       author  \\\n",
       "3502  M.1605148417.A.88C  \"[問卦] 有沒有 Overwatch 還死掉的八卦\"  \"mossdevin\"   \n",
       "\n",
       "                                           content                date  \\\n",
       "3502  \"今天早上 youtube 大家都知道掛掉了 炒得沸沸揚揚  結果有人貼出一個偵測網站\" 2020-11-12 10:33:34   \n",
       "\n",
       "                  ip locale  score  \\\n",
       "3502  180.217.87.229     臺灣      0   \n",
       "\n",
       "                                                    url      board   :LABEL  \\\n",
       "3502  https://www.ptt.cc/bbs/Gossiping/M.1605148417....  Gossiping  PTTPost   \n",
       "\n",
       "                                               keywords  \n",
       "3502  貼出/掛掉/youtube/炒得/有人/Overwatch/死掉/問卦/八卦/偵測/早上/網...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptt_post_nodes.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:START_ID</th>\n",
       "      <th>username</th>\n",
       "      <th>comment</th>\n",
       "      <th>:END_ID</th>\n",
       "      <th>:TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12772</th>\n",
       "      <td>CMT10012772</td>\n",
       "      <td>\"linhsiuwei\"</td>\n",
       "      <td>\"那憑什麼罷免韓國瑜？\"</td>\n",
       "      <td>M.1605261835.A.AA8</td>\n",
       "      <td>COMMENT_OF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76237</th>\n",
       "      <td>CMT10076237</td>\n",
       "      <td>\"jack529\"</td>\n",
       "      <td>\"沒被抓包不就報公帳，這麼簡單還要護航，真的可憐\"</td>\n",
       "      <td>M.1605181924.A.4E3</td>\n",
       "      <td>COMMENT_OF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12376</th>\n",
       "      <td>CMT10012376</td>\n",
       "      <td>\"odaaaaa\"</td>\n",
       "      <td>\"真的很有錢，我是說民進黨\"</td>\n",
       "      <td>M.1605262183.A.5E9</td>\n",
       "      <td>COMMENT_OF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         :START_ID      username                    comment  \\\n",
       "12772  CMT10012772  \"linhsiuwei\"               \"那憑什麼罷免韓國瑜？\"   \n",
       "76237  CMT10076237     \"jack529\"  \"沒被抓包不就報公帳，這麼簡單還要護航，真的可憐\"   \n",
       "12376  CMT10012376     \"odaaaaa\"             \"真的很有錢，我是說民進黨\"   \n",
       "\n",
       "                  :END_ID       :TYPE  \n",
       "12772  M.1605261835.A.AA8  COMMENT_OF  \n",
       "76237  M.1605181924.A.4E3  COMMENT_OF  \n",
       "12376  M.1605262183.A.5E9  COMMENT_OF  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_id_list = list(ptt_post_nodes['PTTPost:ID'])\n",
    "ptt_post_comment_relation = df_ptt_comment2[['commmentId','user','comment','postId']]\n",
    "ptt_post_comment_relation = ptt_post_comment_relation.rename(columns={'commmentId':':START_ID', 'user': 'username',\n",
    "                                                                      'postId': ':END_ID'})\n",
    "ptt_post_comment_relation['in_list'] = ptt_post_comment_relation[':END_ID'].apply(lambda x:if_in_list(x, to_id_list))\n",
    "ptt_post_comment_relation = ptt_post_comment_relation[ptt_post_comment_relation['in_list']==1]\n",
    "del ptt_post_comment_relation['in_list']\n",
    "ptt_post_comment_relation[':TYPE'] = 'COMMENT_OF'\n",
    "# ptt_post_comment_relation[':START_ID'] = ptt_post_comment_relation[':START_ID'].apply(np.int64)\n",
    "ptt_post_comment_relation[\"username\"] = ptt_post_comment_relation[\"username\"].apply(lambda x : replace_double_quote(x))\n",
    "ptt_post_comment_relation[\"username\"] = ptt_post_comment_relation[\"username\"].apply(lambda x : add_quote(x))\n",
    "ptt_post_comment_relation[\"comment\"] = ptt_post_comment_relation[\"comment\"].apply(lambda x : replace_double_quote(x))\n",
    "ptt_post_comment_relation[\"comment\"] = ptt_post_comment_relation[\"comment\"].apply(lambda x : add_quote(x))\n",
    "ptt_post_comment_relation.to_csv('csv/ptt/ptt_post_comment_rel.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "print(ptt_post_comment_relation.shape[0])\n",
    "ptt_post_comment_relation.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"relationship_comment_user\"></a>\n",
    "## Relationship of Comment and User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:START_ID</th>\n",
       "      <th>username</th>\n",
       "      <th>comment</th>\n",
       "      <th>:END_ID</th>\n",
       "      <th>:TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85924</th>\n",
       "      <td>CU100017837</td>\n",
       "      <td>\"ynd\"</td>\n",
       "      <td>\"乾～～～～\"</td>\n",
       "      <td>CMT10085924</td>\n",
       "      <td>COMMENTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         :START_ID username  comment      :END_ID     :TYPE\n",
       "85924  CU100017837    \"ynd\"  \"乾～～～～\"  CMT10085924  COMMENTS"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_id_list = list(ptt_comment_nodes['PTTComment:ID'])\n",
    "ptt_user_comment_relation = df_ptt_comment[['user','comment','commmentId']]\n",
    "ptt_user_comment_relation[\":START_ID\"] = ptt_user_comment_relation[\"user\"].map(user_id_map)\n",
    "ptt_user_comment_relation = ptt_user_comment_relation.rename(columns={'user': 'username',\n",
    "                                                                      'commmentId': ':END_ID'})\n",
    "ptt_user_comment_relation['in_list'] = ptt_user_comment_relation[':END_ID'].apply(lambda x:if_in_list(x, to_id_list))\n",
    "ptt_user_comment_relation = ptt_user_comment_relation[ptt_user_comment_relation['in_list']==1]\n",
    "del ptt_user_comment_relation['in_list']\n",
    "ptt_user_comment_relation[':TYPE'] = 'COMMENTS'\n",
    "# ptt_user_comment_relation[':START_ID'] = ptt_user_comment_relation[':START_ID'].apply(np.int64)\n",
    "ptt_user_comment_relation = ptt_user_comment_relation[[\":START_ID\",\"username\",\"comment\",\":END_ID\",\":TYPE\"]]\n",
    "ptt_user_comment_relation[\"username\"] = ptt_user_comment_relation[\"username\"].apply(lambda x : replace_double_quote(x))\n",
    "ptt_user_comment_relation[\"username\"] = ptt_user_comment_relation[\"username\"].apply(lambda x : add_quote(x))\n",
    "ptt_user_comment_relation[\"comment\"] = ptt_user_comment_relation[\"comment\"].apply(lambda x : replace_double_quote(x))\n",
    "ptt_user_comment_relation[\"comment\"] = ptt_user_comment_relation[\"comment\"].apply(lambda x : add_quote(x))\n",
    "ptt_user_comment_relation.to_csv('csv/ptt/ptt_user_comment_rel.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "print(ptt_user_comment_relation.shape[0])\n",
    "ptt_user_comment_relation.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import_neo4j\"></a>\n",
    "## Import to Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ".\\bin\\neo4j-admin import --nodes=import/ptt_comment_nodes.csv --nodes=import/ptt_post_nodes.csv --nodes=import/post_keyword_nodes.csv --relationships=import/ptt_user_comment_rel.csv --nodes=import/ptt_user_nodes.csv --relationships=import/ptt_user_post_rel.csv --relationships=import/ptt_post_comment_rel.csv --relationships=import/ptt_post_keyword_rel.csv --relationships=import/ptt_comment_keyword_rel.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cypher\"></a>\n",
    "## Cypher query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "MATCH p=( (n:PTTUser)-[r1]-(n1)-[*0..2]->(nd) ) \n",
    "RETURN * LIMIT 25\n",
    "```\n",
    "\n",
    "```python\n",
    "MATCH p=( (n:PTTUser)-[*1..2]-(m) ) \n",
    "RETURN * LIMIT 25\n",
    "```\n",
    "\n",
    "```python\n",
    "MATCH (n:Keywords{keyword:\"道歉\"})-[*1..2]-(m:PTTUser) RETURN * LIMIT 25\n",
    "```\n",
    "\n",
    "```python\n",
    "MATCH (n:PTTPost)-[r:POSTS]-(m:PTTUser) RETURN * limit 25\n",
    "```\n",
    "\n",
    "```python\n",
    "MATCH (n:PTTUser)-[r:POSTS]-(m:PTTUser),(n:PTTUser)-[r2:COMMENTS]-(o:PTTComment) RETURN * LIMIT 25\n",
    "```\n",
    "\n",
    "```python\n",
    "MATCH (n:PTTUser)-[r1:COMMENTS]-(o:PTTComment)-[r2:COMMENT_OF]-(p:PTTPost)-[r3:COMMENT_OF]-(c:PTTComment) RETURN * LIMIT 25\n",
    "```\n",
    "\n",
    "```python\n",
    "MATCH (n:PTTUser)-[r1:COMMENTS]-(o:PTTComment)-[r2:COMMENT_OF]-(p:PTTPost)-[r3:COMMENT_OF]-(c:PTTComment)-[r4:COMMENTS]-(q:PTTUser) RETURN * LIMIT 25\n",
    "```\n",
    "\n",
    "```python\n",
    "MATCH (n:PTTUser)-[r1:COMMENTS]-(o:PTTComment)-[r2:COMMENT_OF]-(p:PTTPost)-[r3:COMMENT_OF]-(c:PTTComment)-[r4:COMMENTS]-(n) RETURN * LIMIT 25\n",
    "```\n",
    "\n",
    "```python\n",
    "MATCH (n:PTTUser)-[r1:POSTS]-(m),(n:PTTUser)-[r2:COMMENTS]-(o:PTTComment)-[r3:COMMENT_OF]-(p:PTTPost) RETURN * LIMIT 25\n",
    "```\n",
    "\n",
    "```python\n",
    "MATCH (n:PTTUser)-[r1:POSTS]-(m),(n:PTTUser)-[r2:COMMENTS]-(o:PTTComment)-[r3:COMMENT_OF]-(p:PTTPost)-[r3:COMMENT_OF]-(c:PTTComment) RETURN * LIMIT 25\n",
    "```\n",
    "\n",
    "```python\n",
    "MATCH (n:PTTUser)-[r1:POSTS]-(m),(n:PTTUser)-[r2:COMMENTS]-(o:PTTComment)-[r3:COMMENT_OF]-(p:PTTPost)-[r4:COMMENT_OF]-(c:PTTComment)-[r5:COMMENTS]-(u:PTTUser) RETURN * LIMIT 25\n",
    "```\n",
    "\n",
    "```python\n",
    "MATCH (n:PTTUser)-[r1:POSTS]-(m),(n:PTTUser)-[r2:COMMENTS]-(o:PTTComment)-[r3:COMMENT_OF]-(p:PTTPost)-[r4:COMMENT_OF]-(c:PTTComment)-[r5:COMMENTS]-(n) RETURN * LIMIT 25\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this practice, we don't extract keyword, hashtag, maybe you could add more nodes, relationship by reference last lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "- Please change collection from your MongoDB.\n",
    "- Create more nodes and relationships."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
